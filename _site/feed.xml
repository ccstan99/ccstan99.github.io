<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2023-06-01T00:26:40-07:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">ccstan99</title><subtitle>ccstan99&apos;s learning journal</subtitle><author><name>ccstan99</name></author><entry><title type="html">Demystifying ChatGPT + LLMs</title><link href="http://localhost:4000/2023/05/24/chatgpt-llms.html" rel="alternate" type="text/html" title="Demystifying ChatGPT + LLMs" /><published>2023-05-24T00:00:00-07:00</published><updated>2023-05-24T00:00:00-07:00</updated><id>http://localhost:4000/2023/05/24/chatgpt-llms</id><content type="html" xml:base="http://localhost:4000/2023/05/24/chatgpt-llms.html"><![CDATA[<p>Welcome to the world of ChatGPT and LLMs filled with alphabet soup jargon. We’ll look at language models, how they got so large, and think about how to deal with all this AI buzz.</p>

<h2 id="background-in-natural-language-processing-nlp">Background in Natural Language Processing (NLP)</h2>

<p>Language models live in the field of natural language processing, The ultimate dream, the holy grail, is to talk with computers just like talking with any other person and have it completely understand you. No need to learn computer languages. They can speak ours. Originally, linguists would painstakingly create “expert” systems, hand-coding  grammar rules and all the vocabulary. Unfortunately, the end results were mediocre, at best.</p>

<p><img src="/img/posts/2023-05-24-llms-stats.png" alt="Statistics in LLMs" /></p>

<p>Towards the late 90s, statistical methods were used. There’s a famous quote, “You shall know a word by the company it keeps.” That simple idea was profound. If you start counting words and looking at what other words tend to occur with it, you’ll end up learning a lot about the language itself. All those relationships make up the language model. Think back to when you were first learning your native language. As a child, you were immersed with sounds, words, and sentences of your language. Now, you have intuition of what sounds right or what’s off, even if you don’t know why. You’ve internalized all the statistics for your own language model.</p>

<h2 id="rise-of-transformers">Rise of Transformers</h2>

<p>Transformers are a special kind of neural network introduced by Google in 2017.</p>

<p>Before that, language models were painfully slow and forgetful. Imagine a sweet old granny struggling to understand words one by one and getting confused by long sentences. So, if you had tried to make models bigger, trained on more data, it didn’t matter.</p>

<p><img src="/img/posts/2023-05-24-llms-superhero.png" alt="Transformers are Superheroes" /></p>

<p>Things didn’t really improve much until Transformers came along with attention superpowers. Now, models could look at everything, all at once. Long-term memory? No problem. Now, we can train on all of Wikipedia and piles and piles of books. The models kept learning and improving. Turns out, neural networks are extremely data hungry. They need tons of it to learn. So people went out and scraped everything they could find on the web: blogs, tweets, code, whatever was out there.</p>

<p>Another innovation: Transformers could process data in parallel. Otherwise, it’s like one checkout stand serving 100 customers one at a time, sequentially. Instead, Transformers use 100 checkout stands to serve all 100 customers at the same time in parallel. So models got bigger, running faster, training longer on more data, and performance kept getting better!</p>

<p>Thus began the rise of large language models. Size is measured by the number of parameters or neurons. Today, to be large, a language model must have at least 1 billion neurons. They’re not the same, but for reference, the human brain has around 85 billion. And all the large language models today are some variant of Transformers, which completely revolutionized AI beyond just language!</p>

<h2 id="generative-pre-trained-transformers-gpt">Generative pre-trained transformers (GPT)</h2>

<p>Generative pre-trained transformers or GPT shine at generating text.</p>

<p>They are trained for next word prediction. It’s like a play the game. You grab a book, pick a sentence, and show the model the beginning of the sentence. It tries to guess the next word in the sentence. You show it the actual next word. Hmm, if it’s wrong, let’s update the neurons to do better the next time. Pick another sentence. Guess another word and update. Then repeat until the model gets really good at guessing the next words. Starting with “Twinkle Twinkle Little…” the next word is most likely “Star.” Maybe feels like a sophisticated auto-complete. Think about when you’re talking with someone and you “complete each other’s sentences.” It’s often a sign of deep mutual understanding. Imagine a computer doing the same.</p>

<p><img src="/img/posts/2023-05-24-llms-training.jpg" alt="Pre-Training LLMs" /></p>

<p>When it comes to P in Pre-training we need to look to the past. A variety of different models would be trained as specialists: one for answering questions, another for classifying things, or for translation. But GPT is a generalist, pre-trained to understand human languages in general, which can be quickly fine-tuned on top of the pre-trained base.</p>

<p>GPT was created by OpenAI. The original, GPT-1, was introduced in 2018, jumping in after Google’s transformers. The next year, GPT-2 was 10 times larger. The year after that, GPT-3 was 100 times larger. By then, it was almost impossible to tell what’s generated and what’s not. As for GPT-4 that just came out? It’s a secret. Keep in mind, these models are huge. It costs millions of dollars to train on a slew of computers over a period of months. It’s not feasible for individuals or even academic researchers to train anything like this. You need those deep pockets.</p>

<h2 id="chatgpt">ChatGPT</h2>

<p>Then along came ChatGPT. Frankly, many working in the field were baffled, “Why is this going viral now? It’s just GPT-3.5, with minor tweaks to the base model released three years ago!”</p>

<p>The secret sauce was reinforcement learning from human feedback. Remember, GPT was trained to predict the next word given the start of a sentence. That’s great for learning the language, but really, that’s not as helpful for the typical end user. When you talk to people, you rarely begin a sentence and then expect them to complete it. Instead, you’re more likely to tell them to do something or maybe ask a question.</p>

<p>So GPT-3 was fine-tuned to respond to instructions. They got lots of sample instructions along with what’s expected. If you see “Prepare a report,” the output should indicate what a report looks like. For “Give me a summary,” the output should indicate what a summary looks like.</p>

<p><img src="/img/posts/2023-05-24-llms-instruct.jpg" alt="ChatGPT was Fine-tuned on Instructions" /></p>

<p>Next, it was also fine-tuned on sample back-and-forth conversations to learn how dialogues work. These extra fine-tuning steps were quick and cheap compared to pre-training the original, which took months and millions. It managed to bring out some innate abilities hidden in the base model. But suddenly, following instructions and carrying conversations made it extremely helpful and eerily “human.”</p>

<h2 id="on-the-horizon">On the Horizon</h2>

<p>That us up to late last year. Now, things are moving even faster since then. Let me point out a few items on the horizon to keep an eye on.</p>

<dl>
  <dt>Multi-modality</dt>
  <dd>Language models deal mainly with text. Multi-modality allows them to use audio, images, and videos to understand the world. And the better to see you, to hear you, and to interact with you.</dd>
  <dt>Open-Source</dt>
  <dd>Just a few weeks ago, Meta released an open-sourced large language model that can run on personal computers. That led to a flurry of activity. Researchers are now creating much smaller and cheaper models that are still powerful.</dd>
  <dt>Agents</dt>
  <dd>Language models can generate text for a plan. Now, they can also call agents, which are programs to execute that plan. “Plan a trip to Tokyo.” It goes to compare prices, book flights, find lodging. You just show up and enjoy. But if AI automatically connects to agents that can change things in the real world with consequences, we must stop and think, “What could possibly go wrong?!”</dd>
</dl>

<h2 id="hype-or-reality">Hype or Reality?</h2>

<p>Is this all hype? Or is the world really changing? I started working in tech during the dot-com era. The gold rush euphoria feels suspiciously familiar. But there’s definitely a fundamental paradigm shift that’s both thrilling but a tad worrying.</p>

<p>Personally, I use large language models every day. They’re great for mundane tasks like proofreading documents, drafting emails, or generating code snippets. Search is really handy. Information is synthesized and summarized for your specific case. But I only use AI as a tool to speed up my normal workflow. I still double-check the output since it’s not all sunshine and rainbows.</p>

<p>You must understand the limitations. Hallucinations are a big problem. That’s a technical term when the output is just flat out wrong but sounds really convincing and confident. A dangerous combination. Essentially, AI is a master B.S.er, but plenty of humans are too. It’s just regurgitating what’s learned from its training data, which includes lots of toxic and biased stuff too. So what’s the key takeaway?</p>

<h2 id="conclusion">Conclusion</h2>

<p>We’re standing at the dawn of this new era shaped by AI. In order to survive, you’ll have to embrace AI in some way. No one wants to be the dinosaur. Sometimes, it feels like we’re blindly rushing into this awe-inspiring yet potentially treacherous territory. AI is a tool that holds immense power, but it’s far from perfect or even safe. As the saying goes, “Trust but verify.” We need to keep humans in the loop. My hope is that we can be guided by wisdom, empathy, and a commitment to embrace the power of AI responsibly.</p>

<p><img src="/img/posts/2023-05-24-llms-embrace.png" alt="Embrace AI Responsibly" /></p>]]></content><author><name>ccstan99</name></author><summary type="html"><![CDATA[Welcome to the world of ChatGPT and LLMs filled with alphabet soup jargon. We’ll look at language models, how they got so large, and think about how to deal with all this AI buzz.]]></summary></entry><entry><title type="html">Google I/O 2023</title><link href="http://localhost:4000/2023/05/10/google-io.html" rel="alternate" type="text/html" title="Google I/O 2023" /><published>2023-05-10T00:00:00-07:00</published><updated>2023-05-10T00:00:00-07:00</updated><id>http://localhost:4000/2023/05/10/google-io</id><content type="html" xml:base="http://localhost:4000/2023/05/10/google-io.html"><![CDATA[<p><a href="https://io.google/2023/">Google I/O 2023</a> proved to be a memorable experience in so many ways!</p>

<h2 id="pre-reception">Pre-Reception</h2>

<p>The event kicked off with the Women Techmakers Ambassadors at the pre-reception on Tuesday evening. It was such an exciting moment to finally meet and connect with Creatives in Tech in person. We were buzzing with anticipation, eager to learn from each other and soak up all the knowledge and inspiration that awaited us.</p>

<p><img src="/img/posts/2023-05-10-io-reception.jpg" alt="evening reception" /></p>

<h2 id="keynote-at-shoreline">Keynote at Shoreline</h2>

<p>One of the highlights of the event was undoubtedly the I/O keynote addresses. It was wonderful to witness Google’s announcements firsthand and watch the impressive AI/ML demos. The entire event was incredibly well-organized, right from the convenient shuttle services to the delicious breakfast and lunch options. And to our surprise, we were even provided with caps, sweatshirts, sunscreen, rain ponchos, and hand warmers - they truly had us covered for any unexpected weather or situation.</p>

<p><img src="/img/posts/2023-05-10-io-keynote.jpg" alt="morning keynotes" /></p>

<h2 id="breakouts-at-bay-view">Breakouts at Bay View</h2>

<p>After the keynote, we had the chance to attend breakout sessions at Google’s new Bayview campus. It was an opportunity to delve deeper into topics like women in leadership and AI/ML. The sessions were informative, engaging, and filled with valuable insights. We couldn’t resist exploring the beautiful campus and taking advantage of the bike trails. It was a refreshing way to unwind and enjoy the surroundings.</p>

<p><img src="/img/posts/2023-05-10-io-bayview.jpg" alt="afternoon breakouts" /></p>

<p>I had such a fantastic time at Google I/O 2023 and highly recommend attending the event in the future. The atmosphere was fun-filled, the knowledge-sharing was inspiring, and the connections made were invaluable. Can’t wait for next time!</p>

<p>Until then, keep exploring, learning, and embracing the exciting world of technology!</p>]]></content><author><name>ccstan99</name></author><summary type="html"><![CDATA[Google I/O 2023 proved to be a memorable experience in so many ways!]]></summary></entry><entry><title type="html">Chatbot with Your Data</title><link href="http://localhost:4000/2023/03/31/chatgpt.html" rel="alternate" type="text/html" title="Chatbot with Your Data" /><published>2023-03-31T00:00:00-07:00</published><updated>2023-03-31T00:00:00-07:00</updated><id>http://localhost:4000/2023/03/31/chatgpt</id><content type="html" xml:base="http://localhost:4000/2023/03/31/chatgpt.html"><![CDATA[<ul>
  <li>How do you use LLMs to create chatbots to answer questions for your domain?</li>
  <li>How do you keep the knowledge up-to-date after the model has already been trained?</li>
  <li>How do you ensure generated answers are accurate and avoid hallucinations?</li>
</ul>

<p>Those are some common questions I’ve seen floating around. Unless you’ve been living under a rock, you’re probably aware that ChatGPT, the large language model (LLM) from OpenAI released last November, has taken the world by storm. It’s created excitement but also raised alarm as powerful AIs on the horizon no longer seems as far-fetched science fiction. As such, the group that I’ve been working with to curate quality answers to AI Safety and Alignment questions has been getting an influx of attention and volunteers. In fact, the entire fields has seen a flurry of activity.</p>

<h2 id="ai-safety--alignment-chatbot">AI Safety &amp; Alignment Chatbot</h2>

<p>A <a href="https://www.lesswrong.com/posts/SLRLuiuDykfTdmesK/speed-running-everyone-through-the-bad-alignement-bingo">bounty was placed on LessWrong</a> for a conversational agent educating people on the different approaches to AI Safety and Alignment. Since I’ve been swamped with other work, I only had a couple days to put together a quick prototype. Fortunately, many of the components needed for the project are related to previous work I’ve already done with extractive question answering:</p>

<ol>
  <li>Processing, chunking, and embedding the alignment research dataset</li>
  <li>Using semantic search to retrieve relevant chunks</li>
  <li>Answering the questions based on the chunk</li>
</ol>

<h2 id="chatbot-with-chatgpt">Chatbot with ChatGPT</h2>

<p>Extracting an answer from a chunk of text is slow and the short few-word answer always felt unsatisfying. On March 1, OpenAI made ChatGPT available to programmers using the <code class="language-plaintext highlighter-rouge">gpt-3.5-turbo</code> model through their <a href="https://platform.openai.com/docs/guides/chat">cloud based API</a>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># TODO code for chat completion, model, temperature, context, chat history messages
</span><span class="kn">import</span> <span class="nn">openai</span>

<span class="n">openai</span><span class="p">.</span><span class="n">ChatCompletion</span><span class="p">.</span><span class="n">create</span><span class="p">(</span>
  <span class="n">model</span><span class="o">=</span><span class="s">"gpt-3.5-turbo"</span><span class="p">,</span>
  <span class="n">messages</span><span class="o">=</span><span class="p">[</span>
        <span class="p">{</span><span class="s">"role"</span><span class="p">:</span> <span class="s">"system"</span><span class="p">,</span> <span class="s">"content"</span><span class="p">:</span> <span class="s">"You are a helpful assistant."</span><span class="p">},</span>
        <span class="p">{</span><span class="s">"role"</span><span class="p">:</span> <span class="s">"user"</span><span class="p">,</span> <span class="s">"content"</span><span class="p">:</span> <span class="s">"What is AI Safety?"</span><span class="p">},</span>
    <span class="p">]</span>
<span class="p">)</span>
</code></pre></div></div>

<h2 id="collaborating">Collaborating</h2>

<p>I’m excited to collaborate with other teams who also submitted prototypes and are dedicated to scaling AI safety and alignment education. It’s been great learning from each other and leveraging the best aspects from each project. Some of the notable features from other projects include:</p>

<ul>
  <li>Detailed citations of sources with a streaming GUI</li>
  <li>Using langchain to rephrase standalone improving conversational capabilities</li>
  <li>Suggesting followup questions to keep the conversation flowing</li>
</ul>

<p>There are definitely other areas of improvement we all need to explore in terms of:</p>

<ul>
  <li>Cleaning up the underlying dataset</li>
  <li>Prompt engineering to ensure accuracy and appropriate tone</li>
  <li>More thorough benchmarked testing, UX research, UI design</li>
  <li>Customizing answer generation options based on user’s level and needs</li>
  <li>Experimenting with other document splitting, vector DBs, embeddings &amp; retrieval, LLMs</li>
</ul>

<p>Together look forward to building a better product that can help answer questions based on the rapidly growing body of alignment research literature. If you’re interested in helping, please join us on <a href="https://discord.gg/cSVG2FdX">Rob Mile’s Discord</a>. Feel free to see our current progress on GitHub for the <a href="https://github.com/stampyAI/stampy-chat">chatbot</a> and the <a href="https://github.com/stampyAI/alignment-research-dataset">dataset</a>.</p>

<p>As I’ve been conducting additional research, I’ll continue adding more resources on LangChain, prompt engineering, and fine-tuning a SBERT model below.</p>

<h2 id="prompt-engineering">Prompt Engineering</h2>

<p>As LLMs are getting better at understanding language and generalizing knowledge, the need to train or fine-tune models may be replaced with a need to understand how to interact or prompt LLMs to yield the best results. Below are some resources and guidelines for doing so:</p>

<ul>
  <li><a href="https://github.com/openai/openai-cookbook/blob/main/techniques_to_improve_reliability.md#how-to-improve-reliability-on-complex-tasks">OpenAI Cookbook</a> along with <a href="https://learn.deeplearning.ai/chatgpt-prompt-eng/">DeepLearning.AI on Coursera</a> 1-hour introduction</li>
  <li><a href="https://github.com/dair-ai/Prompt-Engineering-Guide">DAIR.AI</a> has good references to research literature</li>
  <li><a href="https://learnprompting.org/docs/additional">LearnPrompting.org</a> provides basic introduction</li>
  <li><a href="https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/">Lilian Weng’s Blog</a></li>
</ul>

<h2 id="langchain">LangChain</h2>

<p>LangChain is a valuable library that makes it easier to work with LLM from ingesting data by splitting up text and offering abstractions for different vectorstores, embedding models, prompt templates and text generation LLMs. It also handles conversational memory and chaining multiple calls to the LLMs, treating them like agents:</p>

<ul>
  <li><a href="https://python.langchain.com/en/latest/">LangChain Documentation</a></li>
  <li><a href="https://github.com/hwchase17/langchain">LangChain GitHub Repo</a> includes examples</li>
  <li><a href="https://learn.deeplearning.ai/langchain/">DeepLearning.AI on Coursera</a> for 1-hour introduction</li>
</ul>

<h2 id="general-resources">General Resources</h2>

<ul>
  <li><a href="https://arxiv.org/abs/2005.11401">Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks</a></li>
  <li><a href="https://platform.openai.com/docs/guides/chat">ChatGPT</a></li>
  <li><a href="https://github.com/hwchase17/langchain">LangChain</a></li>
  <li><a href="https://www.lesswrong.com/posts/SLRLuiuDykfTdmesK/speed-running-everyone-through-the-bad-alignement-bingo">LessWrong Bounty</a></li>
</ul>]]></content><author><name>ccstan99</name></author><summary type="html"><![CDATA[How do you use LLMs to create chatbots to answer questions for your domain? How do you keep the knowledge up-to-date after the model has already been trained? How do you ensure generated answers are accurate and avoid hallucinations?]]></summary></entry><entry><title type="html">Dare to be Creative in Tech</title><link href="http://localhost:4000/2023/03/22/wtm-iwd.html" rel="alternate" type="text/html" title="Dare to be Creative in Tech" /><published>2023-03-22T00:00:00-07:00</published><updated>2023-03-22T00:00:00-07:00</updated><id>http://localhost:4000/2023/03/22/wtm-iwd</id><content type="html" xml:base="http://localhost:4000/2023/03/22/wtm-iwd.html"><![CDATA[<p>Are you a woman in tech? Do you want to hear from other creative and talented women in the industry? Look no further than the Women Techmakers Ambassador community, Creatives in Tech! On March 22nd, we celebrated International Women’s Day by hosting a virtual event that highlighted the experiences of creative women in tech.</p>

<p><img src="/img/posts/2023-03-22-iwd-promo.jpg" alt="promo" /></p>

<h2 id="our-event">Our Event</h2>

<p>The 6-hour event featured keynote speeches, panel discussions, and even a job board filled with potential job opportunities for creative tech roles.</p>

<dl>
  <dt>Opening: Dare to Bring Diversity to Web 3.0</dt>
  <dd>(10 am PDT / 12pm CDT / 1pm EDT)</dd>
  <dd>Keynote Speaker: Tina Bonner, CEO &amp; Founder Black in Meta</dd>
  <dt>Embracing Creativity in Tech</dt>
  <dd>(11 am PDT / 1pm CDT / 2pm EDT)</dd>
  <dd>Panelists: Kavitha Bangalore and Raj Sree</dd>
  <dd>Moderator: ChengCheng Tan</dd>
  <dt>Break and Job Jam!</dt>
  <dd>(12pm PDT / 2pm CDT / 3pm EDT)</dd>
  <dt>Creative Tech Corner</dt>
  <dd>(1pm PDT / 3pm CDT / 4pm EDT)</dd>
  <dd>Speakers: Vaishnavi Venkata Subramaniam and Ashley Clayton</dd>
  <dt>The Daring Mindset: Design Thinking</dt>
  <dd>(2pm PDT / 4pm CDT / 5pm EDT)</dd>
  <dd>Panelists: Kaylyn Hill and Michelle Ng</dd>
  <dd>Moderator: ChengCheng Tan</dd>
  <dt>How Daring to be Non-Traditional Secured Me a Job</dt>
  <dd>(3pm PDT / 5pm CDT / 6pm EDT)</dd>
  <dd>Keynote Speaker: Alaa Shahin, UX Designer at Univ of Michigan</dd>
</dl>

<p>We had an amazing turnout, with over 140 registrations on <a href="https://www.eventbrite.com/e/dare-to-be-creative-in-tech-tickets-560933706817">EventBrite</a>. <a href="https://gatheround.com/">Gatheround</a>, as our platform, was perfect for adding a creative touch and allowing for an interactive experience.</p>

<h2 id="our-team">Our Team</h2>

<p>It was an immense honor to befriend so many smart and talented Women Techmaker Ambassadors. Our team of 12 volunteers and 9 speakers worked together to create a comprehensive plan that included a general run of show and weekly meetings starting in mid-January. Kaylyn spearheaded the event, guided us withe her vision, and provided extensive planning documents to keep everything on track. Michelle, our wonderful head of marketing, put together a social media toolkit and recruited backend volunteers. I offered input from the early stages and became more active as an organizer towards the end of February, taking time off work to ensure that everything went smoothly. All the volunteers and speakers actively contributed ideas and ultimately formed a sisterly bond.</p>

<p><img src="/img/posts/2023-03-22-iwd-photobooth.png" alt="photobooth" /></p>

<h2 id="join-our-community">Join Our Community</h2>

<p>Overall, it was an incredibly experience and we hope to continue building our community of talented women in tech. If you’re interested in joining us or attending future events, be sure to follow us on <a href="https://www.linkedin.com/company/creatives-in-tech/">LinkedIn</a> and keep an eye out for our next event announcement. We hope to see you there! ⚡️</p>

<p>This event was generously supported by <a href="https://developers.google.com/womentechmakers">Google Women Techmakers</a>, <a href="https://www.mylivestack.com/">WeTransact.Live</a>, and <a href="https://gatheround.com/">Gatheround</a>.</p>]]></content><author><name>ccstan99</name></author><summary type="html"><![CDATA[Are you a woman in tech? Do you want to hear from other creative and talented women in the industry? Look no further than the Women Techmakers Ambassador community, Creatives in Tech! On March 22nd, we celebrated International Women’s Day by hosting a virtual event that highlighted the experiences of creative women in tech.]]></summary></entry><entry><title type="html">TensorFlow Developer Certification</title><link href="http://localhost:4000/2023/02/13/tensorflow-cert.html" rel="alternate" type="text/html" title="TensorFlow Developer Certification" /><published>2023-02-13T00:00:00-08:00</published><updated>2023-02-13T00:00:00-08:00</updated><id>http://localhost:4000/2023/02/13/tensorflow-cert</id><content type="html" xml:base="http://localhost:4000/2023/02/13/tensorflow-cert.html"><![CDATA[<p>Look what I got! I hope return to fill in more details of how I prepared for the exam and some helpful resources. Overall, this was an excellent learning experience that helped me upskill for Artificial Intelligence, Machine Learning, and Deep Learning in a focused manner.</p>

<p><a href="https://www.credential.net/dd29cf54-be96-4380-8b4c-bc4c5971c781#gs.z3o0gx"><img src="/img/posts/2023-02-13-tensorflow-cert.png" alt="TensorFlow Developer Certificate" /></a></p>

<p>For starters, review the candidate handbook very carefully. The DeepLearning.AI on Coursera lays a strong foundation but you’ll need additional hands on practice as well. Be sure you’re comfortable with these topics:</p>

<h2 id="1-introduction-to-tensorflow">1. Introduction to TensorFlow</h2>

<ul>
  <li>Learn best practices for using TensorFlow, a popular open-source machine learning framework</li>
  <li>Build a basic neural network in TensorFlow</li>
  <li>Train a neural network for a computer vision application</li>
  <li>Understand how to use convolutions to improve your neural network</li>
</ul>

<h2 id="2-convolutional-neural-networks-in-tensorflow">2. Convolutional Neural Networks in TensorFlow</h2>

<ul>
  <li>Handle real-world image data</li>
  <li>Plot loss and accuracy</li>
  <li>Explore strategies to prevent overfitting, including augmentation and dropout</li>
  <li>Learn transfer learning and how learned features can be extracted from models</li>
</ul>

<h2 id="3-natural-language-processing-in-tensorflow">3. Natural Language Processing in TensorFlow</h2>

<ul>
  <li>Build natural language processing systems using TensorFlow</li>
  <li>Process text, including tokenization and representing sentences as vectors</li>
  <li>Apply RNNs, GRUs, and LSTMs in TensorFlow</li>
  <li>Train LSTMs on existing text to create original poetry and more</li>
</ul>

<h2 id="4-sequences-time-series-and-prediction">4. Sequences, Time Series and Prediction</h2>

<ul>
  <li>Solve time series and forecasting problems in TensorFlow</li>
  <li>Prepare data for time series learning using best practices</li>
  <li>Explore how RNNs and ConvNets can be used for predictions</li>
  <li>Build a sunspot prediction model using real-world data</li>
</ul>

<h2 id="miscellaneous-tips">Miscellaneous Tips</h2>

<ul>
  <li>Studied additional topics…</li>
  <li>Used both local GPU + Google colabs</li>
  <li>Kept handy code snippets for TensorBoard, early stopping, checkpoints, etc</li>
</ul>

<h2 id="resources">Resources</h2>

<ul>
  <li><a href="https://www.tensorflow.org/certificate">Review Candidate Handbook</a></li>
  <li><a href="https://www.coursera.org/professional-certificates/tensorflow-in-practice">DeepLearning.AI on Coursera</a></li>
  <li><a href="https://github.com/ageron/handson-ml3">Hands-On ML with Scikit-Learn, Keras, and TensorFlow</a></li>
</ul>]]></content><author><name>ccstan99</name></author><summary type="html"><![CDATA[Look what I got! I hope return to fill in more details of how I prepared for the exam and some helpful resources. Overall, this was an excellent learning experience that helped me upskill for Artificial Intelligence, Machine Learning, and Deep Learning in a focused manner.]]></summary></entry><entry><title type="html">Women Techmakers Ambassador</title><link href="http://localhost:4000/2022/12/07/wtm-ambassador.html" rel="alternate" type="text/html" title="Women Techmakers Ambassador" /><published>2022-12-07T00:00:00-08:00</published><updated>2022-12-07T00:00:00-08:00</updated><id>http://localhost:4000/2022/12/07/wtm-ambassador</id><content type="html" xml:base="http://localhost:4000/2022/12/07/wtm-ambassador.html"><![CDATA[<p>I’m delighted to share that I recently became a Google’s Women Techmakers (WTM) Ambassador, joining a vibrant community of over 1000 women from around the world who are passionate about technology and dedicated to fostering equity and diversity in the tech industry. The onboarding introduced me to the program’s mission, resources, and the many ways in which I can contribute to my community.</p>

<p><img src="/img/posts/2022-12-07-wtm-ambassador.gif" alt="I'm a WTM Ambassador!" /></p>

<p>After working in tech for many years now, I’ve gotten to the “sea of dudes”. Until recently, I’d never been involved with any movements geared towards women in tech. I’ve worked with great guys but I’ve realized that working with other women in tech has such a refreshingly nurturing vibe. Now, I’m wondering: Why didn’t I start sooner?!</p>

<h2 id="notification--onboarding">Notification &amp; Onboarding</h2>

<p>In mid-November, I received a notification that I had been selected as a WTM Ambassador. The application process evaluated past leadership experience, so it was humbling to be recognized as part of this global community of change-makers. The global onboarding was held in early December, then followed by the North American onboarding the next week. During these sessions, the WTM team highlighted the diverse ways in which we can contribute to the community’s growth. From speaking at events and organizing meet-ups to mentoring aspiring individuals and creating valuable resources such as blogs or podcasts, the ambassador role is truly multi-faceted. Google also provides continuing development for technical and applied skills. Together, these set the stage for collaboration and global networking.</p>

<h2 id="international-womens-day">International Women’s Day</h2>

<p>The International Women’s Day (IWD) events from March through April are a highlight for WTM. These annual events serve as a powerful platform to celebrate the achievements of women in tech and inspire future generations. Google offers incentives and support to WTM Ambassadors helping contribute to the success of IWD by organizing events, spreading awareness, while making a meaningful impact.</p>

<p>As I embark on this incredible journey as a Women Techmakers Ambassador, I’m filled with excitement and gratitude. I look forward to leveraging my skills and experiences to support others in tech. The opportunity to be a part of a global network of like-minded individuals and the chance to make a tangible impact in my community are priceless.</p>]]></content><author><name>ccstan99</name></author><summary type="html"><![CDATA[I’m delighted to share that I recently became a Google’s Women Techmakers (WTM) Ambassador, joining a vibrant community of over 1000 women from around the world who are passionate about technology and dedicated to fostering equity and diversity in the tech industry. The onboarding introduced me to the program’s mission, resources, and the many ways in which I can contribute to my community.]]></summary></entry><entry><title type="html">Go Attack</title><link href="http://localhost:4000/2022/12/01/goattack-poster.html" rel="alternate" type="text/html" title="Go Attack" /><published>2022-12-01T00:00:00-08:00</published><updated>2022-12-01T00:00:00-08:00</updated><id>http://localhost:4000/2022/12/01/goattack-poster</id><content type="html" xml:base="http://localhost:4000/2022/12/01/goattack-poster.html"><![CDATA[<p>I am thrilled to share my recent helping <a href="http://far.ai">FAR.AI</a>, an AI Alignment research organization, creating the NeurIPS poster for the project <a href="https://goattack.far.ai/">“Adversarial Policies Beat Superhuman Go AIs.”</a></p>

<h2 id="research-overview">Research Overview</h2>

<p>The project, fondly nicknamed “Go Attack”, aimed to challenge the state-of-the-art Go-playing AI system KataGo. Researchers developed adversarial policies designed to play against KataGo. The adversarial policies achieved an astounding win rate of over 99% when KataGo used no tree search, and over 97% when it utilized enough search to be considered superhuman.</p>

<p>What’s even more surprising is that the adversaries did not win by playing Go better than KataGo. In fact, they were easily beaten by human amateurs. Instead, the adversaries won by exploiting weaknesses in KataGo, tricking it into making serious blunders. This attack strategy transferred effortlessly to other superhuman Go-playing AIs, showcasing the surprising failure modes even in the most advanced AI systems.</p>

<h2 id="reworked-figures">Reworked Figures</h2>

<p>To better communicate the research findings, I reworked images from previous presentations and figures, particularly focusing on clarifying the <strong>threat model</strong> and the concept of <strong>non-transitivity</strong> with the unexpected result: If play were transitive, Human players would not beat Adversary! Finally, I incorporated images generated from different Go board configurations to showcase various strategies we employed during testing.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">after</th>
      <th style="text-align: center">before</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/img/posts/2022-12-01-goattack-model.svg" class="cols-2" /><br />Threat Model</td>
      <td style="text-align: center"><img src="/img/posts/2022-12-01-goattack-model-before.png" class="cols-2" /></td>
    </tr>
    <tr>
      <td style="text-align: center"><img src="/img/posts/2022-12-01-goattack-nontransitivity.svg" class="cols-2" /><br />Non-Transitivity</td>
      <td style="text-align: center"><img src="/img/posts/2022-12-01-goattack-nontransitivity-before.png" class="cols-2" /></td>
    </tr>
  </tbody>
</table>

<h2 id="neurips-poster">NeurIPS Poster</h2>

<p>The various figures were crafted into narrative summaring the research journey, highlighting the significant achievements and implications of the findings. In addition to creating the digital poster, I also designed a template for the organization that will be used for future conference presentations.</p>

<p><img src="/img/posts/2022-12-01-goattack.png" alt="GoAttack Poster" /></p>

<h2 id="conclusion">Conclusion</h2>

<p>It was a privilege to make a small contribution to the field of AI safety. Learn more about the project by visiting the <a href="https://goattack.far.ai/">website</a>, reading the <a href="https://arxiv.org/abs/2211.00241">paper</a>, or exploring the <a href="https://github.com/AlignmentResearch/go_attack">code</a>. Special thanks to Adam Gleave for inviting me to help with the project and the many rounds of constructive feedbacks. Thanks also goes to Tony Wang who pointed out that the human figure resembled a cop and thug, which led to strengthening other visual cues such as changing the clothing color and adjusting the direction. Congrats to the team for winning a best paper award and an x-risk analysis award for the NeurIPS 2022 ML Safety Workshop!</p>]]></content><author><name>ccstan99</name></author><summary type="html"><![CDATA[I am thrilled to share my recent helping FAR.AI, an AI Alignment research organization, creating the NeurIPS poster for the project “Adversarial Policies Beat Superhuman Go AIs.”]]></summary></entry><entry><title type="html">Optimal Behavior Prior</title><link href="http://localhost:4000/2022/11/30/obp-poster.html" rel="alternate" type="text/html" title="Optimal Behavior Prior" /><published>2022-11-30T00:00:00-08:00</published><updated>2022-11-30T00:00:00-08:00</updated><id>http://localhost:4000/2022/11/30/obp-poster</id><content type="html" xml:base="http://localhost:4000/2022/11/30/obp-poster.html"><![CDATA[<h2 id="effective-use-of-human-data">Effective Use of Human Data</h2>

<p>Happy Thanksgiving! Would you have liked an AI preparing your feast? Or maybe cleaning up afterwards? On the road to creating collaborative AI agents that can better understand and assist humans, <a href="https://arxiv.org/abs/2211.01602">Optimal Behavior Prior</a> presents an efficient way to use data collected from humans using the <a href="https://github.com/HumanCompatibleAI/overcooked_ai">Overcooked-AI</a> benchmark environment.</p>

<h2 id="figure-rework">Figure Rework</h2>

<p>Through <a href="http://far.ai">FAR.AI</a>, I had the opportunity to design communications for the paper. The main figure was a centerpiece highlighting the key concepts from the paper and an algorithm also clarified the process.</p>

<p><img src="/img/posts/2022-11-30-obp-1a.png" class="border-0" /></p>

<p><img src="/img/posts/2022-11-30-obp-algorithm.png" class="border-0" /></p>

<p>While the original figure was already well-done, we explored other ways to strengthen the ideas by:</p>

<ul>
  <li>Stacking the environments to show a given environment with agents in greater detail.</li>
  <li>Combining the policy, agent, and neural network model images together into a single image emphasized the color &amp; labels more clearly.</li>
  <li>Simplifying the human-data image.</li>
  <li>Adding a narrative storyline with bold keywords to highlight the discrete steps.</li>
  <li>Incorporating subtext from the algorithm underneath keywords added to the explanation.</li>
</ul>

<p><img src="/img/posts/2022-11-30-obp-1b.pn" class="border-0" /></p>

<h2 id="poster-design">Poster Design</h2>

<p>After some additional back &amp; forth to finalize text description and LaTex labels, the newly redesigned figure and other key elements from the paper were extracted to create the resulting poster. Normally, I use Adobe Illustrator or InDesign for layout projects. However, in this case, figures were formatted in Figma then printed on a 2’x3’ poster.</p>

<p><img src="/img/posts/2022-11-30-obp-poster.png" alt="NeurIPS Poster" /></p>

<p>Check out the full paper, <a href="https://arxiv.org/abs/2211.01602">“Optimal Behavior Prior: Data-Efficient Human Models for Improved Human-AI Collaboration”</a> presented at the NeurIPS 2022 Human in the Loop Learning (HiLL) Workshop. Special thanks to Micah Carroll for providing the initial figures, sample poster templates, and constructive feedback throughout the entire process.</p>]]></content><author><name>ccstan99</name></author><summary type="html"><![CDATA[Effective Use of Human Data]]></summary></entry><entry><title type="html">Minimalist Logo</title><link href="http://localhost:4000/2022/11/20/stampy-min-logo.html" rel="alternate" type="text/html" title="Minimalist Logo" /><published>2022-11-20T00:00:00-08:00</published><updated>2022-11-20T00:00:00-08:00</updated><id>http://localhost:4000/2022/11/20/stampy-min-logo</id><content type="html" xml:base="http://localhost:4000/2022/11/20/stampy-min-logo.html"><![CDATA[<h2 id="fun-vs-minimal">Fun vs Minimal</h2>

<p>While some people loved the new Stampy logo, others felt it was a bit too “cutesy” and inappropriate to represent a serious topic as AGI safety and existential risk to humanity. So, an alternate website was launched with the same informational text content as stampy.ai but without the imagery. Between the various sites, the analytics indicated a healthy average of a few thousand visitors each week. We began exploring a more minimalistic logo for these alternate sites.</p>

<h2 id="generated-alignment">Generated Alignment</h2>

<p>With the idea of “alignment” and “seriousness” in mind, we first used namecheap’s <a href="https://www.namecheap.com/logo-maker/app/">Logo Maker</a> to generate some basic ideas. After answering a few questions on our preferences for font and logo styles &amp; colors, we gravitated towards indigo-bluish colors, some gradients, and parallel lines to indicate alignment.
<img src="/img/posts/2022-11-20-stampy-min-ideas1.png" class="width-50" /></p>

<h2 id="puzzling-challenges">Puzzling Challenges</h2>

<p>For the next iteration, we brought in some additional ideas of mazes or puzzles, hinting at the idea of solving challenging problems. Someone suggested using concentric circles or colors from branding within the <a href="https://www.centreforeffectivealtruism.org/">Effective Altruism</a> movement.</p>

<p><img src="/img/posts/2022-11-20-stampy-min-ideas2.jpg" class="width-50" /></p>

<p><img src="/img/posts/2022-11-20-stampy-min-ideas3.png" class="width-50" /></p>

<h2 id="easter-eggs">Easter Eggs</h2>

<p>In our final rounds, we experimented with some Easter eggs, incorporating aspects of the original Stampy colors including elements of a face and stamp.</p>

<p><img src="/img/posts/2022-11-20-stampy-min-ideas4.png" class="width-50" /></p>

<p>Finally, introducing our new alternate, minimalistic, sorta-serious logo… It’s a puzzle. It’s a maze. It’s a stamp. It’s face. It’s anything it wants to be! Do you see all the possibilities?</p>

<p><img src="/img/posts/2022-11-20-stampy-min-logo.svg" class="width-50" /></p>

<p>Take a look at <a href="https://aisafety.info/">aisafety.info</a> with the new, minimalistic design.</p>]]></content><author><name>ccstan99</name></author><summary type="html"><![CDATA[Fun vs Minimal]]></summary></entry><entry><title type="html">AI Alignment Literature</title><link href="http://localhost:4000/2022/09/22/align-lit.html" rel="alternate" type="text/html" title="AI Alignment Literature" /><published>2022-09-22T00:00:00-07:00</published><updated>2022-09-22T00:00:00-07:00</updated><id>http://localhost:4000/2022/09/22/align-lit</id><content type="html" xml:base="http://localhost:4000/2022/09/22/align-lit.html"><![CDATA[<h2 id="alignment-literature-search">Alignment Literature Search</h2>

<p>The field of AI Safety &amp; Alignment is a new and very fluid field of study. There’s been an influx of recent research which makes it a daunting task for those interested in entering the field to get a good overview of the landscape and directions.</p>

<p>For the last few months, getting backing into web development for the Stampy UI and working on the semantic search have been rewarding. Since we functioned well together as a team, a number of software engineers have decided to turn full-time on AGI Safety &amp; Alignment to form the <a href="https://alignment.dev/">Alignment Ecosystem Development</a> group. I’m really excited to start on a new project with them, taking the <a href="https://github.com/moirage/alignment-research-dataset">Alignment Research Dataset</a> to be searchable for AI alignment researchers. This is my excuse er chance to get better acquainted with research literature while also working with some NLP techniques. In the meantime, I’ve also been attending a weekly to biweekly <a href="https://www.agisafetyfundamentals.com/ai-alignment-curriculum">AGI Safety Fundamentals</a> reading group.</p>

<p>Between the reading group and researching for the next project, I’m rapidly drowning in my random piles of handwritten notes. For now, I’ll be using various parts of this site and specificially this page to organize meandering thoughts and track progress, which will likely remain in a state of flux for some time.</p>

<h2 id="prototypes-and-notes">Prototypes and Notes</h2>

<p>Ultimately, I was able to create a few prototypes to demo:</p>

<ul>
  <li><a href="http://nlp.stampy.ai">Semantic Search for Similar Stampy FAQs</a></li>
  <li><a href="https://nlp.stampy.ai/literature">Search Literature Abstracts &amp; Summaries</a></li>
  <li><a href="https://nlp.stampy.ai/extract">Extract Answers from Literature</a></li>
</ul>

<p>These are deployed on Google Cloud Run. This project gave me an excuse to learn about Google Cloud Platform (GCP) and take some Coursera classes by Google on Cloud Computing and App Engineering. It was fascinating, and I learned enough to get my prototypes deployed. Unfortunately, much of reminded me of my tortuous days in IT doing sysadmin, so I was lucky enough to find a knowledgeable guru to save me from my misery.</p>

<h2 id="resources">Resources</h2>

<ul>
  <li><a href="https://arxiv.org/abs/2206.02841">Understanding AI Alignment Research: A Systematic Analysis</a> <a href="https://github.com/moirage/alignment-research-dataset">[GitHub]</a> (2022)</li>
  <li><a href="https://arxiv.org/abs/2004.07180">SPECTER: Document-level Representation Learning using Citation-informed Transformers</a> <a href="https://github.com/allenai/specter">[GitHub]</a> (2020)</li>
  <li><a href="https://arxiv.org/abs/2004.15011">TLDR: Extreme Summarization of Scientific Documents</a> <a href="https://github.com/allenai/scitldr">[GitHub]</a> (2020)</li>
  <li><a href="https://arxiv.org/abs/1903.10676v3">SCIBERT: A Pretrained Language Model for Scientific Text</a> <a href="https://github.com/allenai/scibert">[GitHub]</a> (2019)</li>
  <li><a href="https://arxiv.org/abs/1903.10676v3">S2ORC: The Semantic Scholar Open Research Corpus</a> <a href="https://github.com/allenai/s2orc">(GitHub)</a> (2019)</li>
  <li><a href="https://arxiv.org/abs/1805.02262">Construction of the Literature Graph in Semantic Scholar</a> (2018)</li>
</ul>

<h2 id="open-domain-qa">Open Domain Q&amp;A</h2>

<ul>
  <li><a href="https://aclanthology.org/2020.acl-tutorials.8/">ACL2020 Tutorial: Open-Domain Question Answering</a> <a href="https://github.com/danqi/acl2020-openqa-tutorial">[GitHub]</a> (2020)</li>
  <li><a href="https://arxiv.org/abs/2209.10063">Generate rather than Retrieve: Large Language Models are Strong Context Generators</a></li>
  <li><a href="https://arxiv.org/abs/2009.08553">Generation-Augmented Retrieval for Open-domain Question Answering</a></li>
  <li><a href="https://arxiv.org/abs/2004.04906">Dense Passage Retrieval for Open-Domain Question Answering</a></li>
  <li><a href="https://arxiv.org/abs/1704.00051">Reading Wikipedia to Answer Open-Domain Questions</a></li>
</ul>

<h2 id="vector-databases-and-building-ml-apps">Vector Databases and Building ML Apps</h2>

<ul>
  <li><a href="https://milvus.io/">milvus</a> <a href="https://github.com/milvus-io/bootcamp">[GitHub]</a></li>
  <li><a href="https://www.pinecone.io/learn/">pinecone</a> <a href="https://github.com/pinecone-io">[GitHub]</a></li>
  <li><a href="https://www.gradio.app/getting_started/">gradio</a> <a href="https://github.com/gradio-app">[GitHub]</a></li>
  <li><a href="https://docs.streamlit.io/library/get-started">streamlit</a> <a href="https://github.com/streamlit">[GitHub]</a></li>
</ul>]]></content><author><name>ccstan99</name></author><summary type="html"><![CDATA[Alignment Literature Search]]></summary></entry></feed>