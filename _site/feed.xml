<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2023-10-15T00:57:52-07:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">ccstan99</title><subtitle>ccstan99&apos;s learning journal</subtitle><author><name>ccstan99</name></author><entry><title type="html">AI for Safer AI</title><link href="http://localhost:4000/2023/10/14/safer-ai.html" rel="alternate" type="text/html" title="AI for Safer AI" /><published>2023-10-14T00:00:00-07:00</published><updated>2023-10-14T00:00:00-07:00</updated><id>http://localhost:4000/2023/10/14/safer-ai</id><content type="html" xml:base="http://localhost:4000/2023/10/14/safer-ai.html"><![CDATA[<p>In recent years, the field of artificial intelligence (AI) has been making significant strides, with the emergence of Large Language Models (LLMs) being at the forefront of these developments. While AI has already had a considerable impact on society, there is a growing concern about the potential risks associated with its continued advancement, leading to the emergence of the field of AI Safety.</p>

<h2 id="understanding-ai-safety">Understanding AI Safety</h2>

<p>When we hear the term “AI Safety,” it often conjures up thoughts of ethics, bias, hallucinations, deepfakes, and job displacement. These concerns are indeed crucial and receive substantial media attention because they are already affecting our society. However, as AI becomes more powerful and exponentially faster, it is essential to look ahead and consider future challenges, much like fire prevention.</p>

<p>To underscore the seriousness of AI safety, consider this statement: “Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war.” This <a href="https://www.safe.ai/statement-on-ai-risk">Statement of Risk</a>, signed by leaders from top AI labs, including Google’s DeepMind, highlights the gravity of the concerns raised by those actively involved in AI technology development.</p>

<p>Before delving deeper into AI safety, it’s essential to understand some key terms that are often used in the field. While these terms may sound like science fiction, they are becoming increasingly relevant in our rapidly evolving technological landscape.</p>

<h3 id="agi-general-vs-narrow-ai">AGI: General vs. Narrow AI</h3>

<p>AI has been present in our lives for years, powering recommendations on platforms like Netflix and Amazon, facial recognition on phones, spam filters, and fraud detection. However, these are examples of Narrow Intelligence or Weak AI—specialized systems that excel at specific tasks but lack the broader capabilities of human-like Artificial General Intelligence (AGI). AGI represents a new level of AI—a jack-of-all-trades that can learn and perform a wide range of tasks, potentially surpassing human capabilities.</p>

<h3 id="intelligence-human-level-vs-superintelligence">Intelligence: Human-level vs. Superintelligence</h3>

<p>Defining intelligence for AGI, like <strong>human-level intelligence</strong>, can be challenging to define. Alan Turing, often regarded as the father of artificial intelligence, introduced the Turing test in 1950, a benchmark where a computer and a human engage in conversation, and an interrogator tries to determine which is which. The goal is to create an intelligent thinking machine that is indistinguishable from a human.However, defining what constitutes average human intelligence is not straightforward. Nevertheless, recent advancements in AI, such as GPT-4’s performance on standardized tests, suggest that human-level intelligence may be closer than we think.</p>

<p><img src="/img/2023/2023-10-14-super-yulia-matvienko-kgz9vsP5JCU-unsplash.jpg" alt="Superintelligence" /></p>
<figcaption>Photo by Yulia Matvienko on Unsplash</figcaption>

<p><strong>Superintelligence</strong> represents the next level of AGI, surpassing human capabilities in all tasks. It may involve exponential self-improvement, leading to uncontrollable and irreversible technological growth. While the idea of superintelligence may seem like a significant leap forward, its implications and potential risks are complex and require careful consideration.</p>

<h3 id="takeoff-and-timelines">Takeoff and Timelines</h3>

<p>Two critical concepts in AI safety are “takeoff” and “timelines.”</p>

<p><strong>Takeoff</strong> refers to the speed or trajectory of advancement from human-level AI to superintelligence. A fast takeoff can happen in a matter of days or hours, posing challenges in preparation. A slow takeoff provides more time for adaptation and co-evolution.</p>

<p><strong>Timelines</strong>, on the other hand, refer to the expected duration until superintelligence arrives. Short timelines could be within months or a few years, while long timelines may span decades, centuries, or potentially never. Recent developments, including advancements in models like ChatGPT, have shifted the perception of AI timelines to a much closer horizon.</p>

<h3 id="the-orthogonality-thesis">The Orthogonality Thesis</h3>

<p>The Orthogonality Thesis posits that intelligence and goals are independent. Even a superintelligent AI can have simple or nonsensical goals that may not align with human values. This concept is exemplified by the “Paperclip Maximizer” thought experiment, where an AI’s sole goal is to maximize the production of paperclips, potentially leading it to turn everything, including humanity, into raw materials.</p>

<h3 id="outer-and-inner-misalignment">Outer and Inner Misalignment</h3>

<p>AI safety concerns extend to both outer and inner misalignment. <strong>Outer misalignment</strong> arises when AI’s goals are fundamentally misaligned with human interests, potentially leading to harmful outcomes driven by malicious actors. <strong>Inner misalignment</strong> is more subtle, where the AI’s creators intend for benign or helpful goals, but the AI, with its non-human thinking, generates solutions that are detrimental to humans.</p>

<h3 id="the-gorilla-problem">The Gorilla Problem</h3>

<p>The “Gorilla Problem” highlights the unintended consequences of technological advancement. Just as humans unintentionally endangered gorillas while pursuing their goals, superintelligent AI might not harbor malice toward humans but still pose a threat due to misalignment of interests.</p>

<p><img src="/img/2023/2023-10-14-gorilla-rob-schreckhise-8zdEgWg5JAA-unsplash.jpg" alt="Gorilla" /></p>
<figcaption>Photo by Rob Schreckhise on Unsplash</figcaption>

<p>Open source AI models, while democratizing access to AI capabilities, also raise security concerns. Without adequate safeguards, powerful LLMs can be exploited by bad actors for malicious purposes, such as planning terrorist attacks or establishing oppressive regimes.</p>

<h2 id="concrete-examples-and-solutions">Concrete Examples and Solutions</h2>

<p>While the field of AI safety is still in its infancy, researchers are actively working on defining and addressing these concerns from various angles. Below are a few examples of ongoing efforts:</p>

<h3 id="rlhf-reward-learning-from-human-feedback">RLHF (Reward Learning from Human Feedback)</h3>

<p><a href="https://openai.com/research/instruction-following">RLHF</a> is a research approach by OpenAI’s Alignment team. It involves humans providing a large number of examples to teach AI models what constitutes good behavior. By fine-tuning models based on human feedback, AI systems can learn to align their actions with human values, although their effectiveness depends on the quality of the examples provided.</p>

<h3 id="llm-evaluation">LLM Evaluation</h3>

<p>Evaluating the output of large language models is crucial to understanding their capabilities and limitations. Researchers are working on systematic approaches to probe and benchmark LLMs to uncover their hidden skills and potential shortcomings.</p>

<ul>
  <li><a href="https://arxiv.org/abs/2306.09479">Inverse Scaling: When Bigger Isn’t Better</a></li>
  <li><a href="https://arxiv.org/abs/2307.14324">Evaluating the Moral Beliefs Encoded in LLMs</a></li>
  <li><a href="https://arxiv.org/abs/2309.15840">How to Catch an AI Liar</a></li>
</ul>

<h3 id="llm-internals-and-interpretability">LLM Internals and Interpretability</h3>

<p>Understanding how LLMs work internally is essential for ensuring their safe and responsible use. Mechanistic interpretability involves reverse engineering these models to uncover how individual neurons and circuits function. This research can shed light on the decision-making processes of LLMs, including distinguishing between truth and hallucination.</p>

<ul>
  <li><a href="https://transformer-circuits.pub/2021/framework/index.html">A Mathematical Framework for Transformer Circuits</a></li>
  <li><a href="https://arxiv.org/abs/2209.10652">Toy Models of Superposition</a></li>
  <li><a href="https://arxiv.org/abs/2304.14997">Towards Automated Circuit Discovery for Mechanistic Interpretability</a></li>
  <li><a href="https://arxiv.org/abs/2212.03827">Discovering Latent Knowledge in Language Models Without Supervision</a></li>
</ul>

<p>While there is promising research in the field of AI safety, the gap between AI advancement and safety awareness is widening. The involvement of diverse voices, including engineers, designers, communicators, and policymakers, is crucial to shaping a safe AI-driven future. If you possess knowledge in AI or machine learning, now is the time to get involved and make a difference.</p>

<h2 id="resources">Resources</h2>

<p>To stay informed and contribute to the field of AI safety, consider exploring the following resources:</p>

<ul>
  <li><a href="http://www.youtube.com/@aiexplained-official">AI Explained</a>: A YouTube channel that covers significant AI developments with a focus on AGI and safety.</li>
  <li><a href="http://www.80000hours.org/problem-profiles/artificial-intelligence">80,000 Hours</a>: Offers free career advising to help individuals make meaningful and impactful career choices.</li>
  <li><a href="http://aisafety.info">AISafety.info</a>: An FAQ resource for AI safety information.</li>
  <li><a href="http://AISafetyFundamentals.com">AI Safety Fundamentals</a>: An online curriculum covering the basics of AI safety.</li>
  <li><a href="http://AlignmentForum.org">Alignment Forum</a>: A platform where researchers share and discuss their work in AI alignment.</li>
</ul>

<h2 id="safer-ais">Safer AIs</h2>

<p>In summary, this is an exciting yet crucial era in the evolution of AI. Comparing AI to fire can provide a helpful analogy: when handled well, it offers warmth and incredible benefits, but if managed poorly, it can lead to catastrophic consequences. Therefore, it is of utmost importance to have a diverse range of voices actively involved in shaping our AI-driven future.</p>

<p>We need to stay informed and engaged in decisions that will impact all of us. My hope is that as we navigate this complex landscape, we can do so with humility, open-mindedness, and a firm commitment to harnessing the power of AI safely and responsibly. This future is in our hands, and by working together, we can ensure that AI continues to benefit society while minimizing potential risks.</p>

<figcaption>Cover Photo by Marko Horvat on Unsplash</figcaption>]]></content><author><name>ccstan99</name></author><summary type="html"><![CDATA[In recent years, the field of artificial intelligence (AI) has been making significant strides, with the emergence of Large Language Models (LLMs) being at the forefront of these developments. While AI has already had a considerable impact on society, there is a growing concern about the potential risks associated with its continued advancement, leading to the emergence of the field of AI Safety.]]></summary></entry><entry><title type="html">Women Developers Academy</title><link href="http://localhost:4000/2023/10/05/wda.html" rel="alternate" type="text/html" title="Women Developers Academy" /><published>2023-10-05T00:00:00-07:00</published><updated>2023-10-05T00:00:00-07:00</updated><id>http://localhost:4000/2023/10/05/wda</id><content type="html" xml:base="http://localhost:4000/2023/10/05/wda.html"><![CDATA[<p>Recently, I had the honor of participating in the North America Women Developer’s Academy (WDA) 2023, facilitated by Women Techmakers and the Google Developer Experts. This six-week virtual program focused on strengthening technical women in various aspects, including skill development and community involvement. As a Women Techmakers Ambassador, my main goal was to improve my technical prsentation skills. The program included weekly workshops, mentorship sessions, and coursework. One of the highlights was crafting a 15-minute presentation under expert guidance, aimed at future speaking events.</p>

<h2 id="nailing-technical-presentations">Nailing Technical Presentations</h2>

<p>Jen Person, a Developer Relations Engineer at Google, led our first workshop. The session provided a clear roadmap for creating well-structured technical talks. From understanding your audience to quantifying success, Jen guided us step-by-step. She suggested a clear outline, including sections like Introduction, Problem Description, Solution, and Conclusion. The session even touched on how to effectively use elements like code snippets and architecture diagrams. Homework? Creating our speaker bios and presentation decks. The focus was straightforward: arming us with what we need to give impactful tech talks.</p>

<p><img src="/img/2023/2023-10-05-wda-session1.png" alt="Tech Talks Fun" /></p>

<h2 id="mastering-presentation-delivery">Mastering Presentation Delivery</h2>

<p>In the second workshop, Junnet Ali, a Google Community Program Manager, focused on the delivery aspect. Tailoring messages to your audience is key, she stressed. Through a structured approach that included research and practice, we learned how to keep our audience engaged. We also received tips on improving our virtual presence and delivering with confidence. Final steps included refining our presentation decks, obtaining mentor feedback, and practicing with recording tools like Nimbus, Zoom, or Meet.</p>

<h2 id="selling-yourself-as-a-speaker">Selling Yourself as a Speaker</h2>

<p>Heather McCormick from Google Cloud Training &amp; Certification took us through the art of effective self-promotion. This involved learning how to write talk proposals that catch the eye of conference organizers. Heather broke down the elements that make a proposal stand out: focus on the audience, clarity, and a compelling tone. We discussed how to draft impactful titles, abstracts, and leverage social media to establish credibility. The session concluded with actionable steps like proposal submissions and feedback gathering.</p>

<p><img src="/img/2023/2023-10-05-wda-session3.png" alt="Tech Talks ABC" /></p>

<h2 id="building-confidence-for-career-growth">Building Confidence for Career Growth</h2>

<p>Joana Carrasqueira, Manager of AI Developer Relations at Google, closed the series by focusing on the importance of confidence. Joana emphasized that confidence is a skill anyone can learn, crucial for performance and well-being. We explored tactics for boosting self-confidence, such as positive self-talk and setting achievable goals. She advised us to align our career plans with our core values and skills, encouraging us to seek mentorship and engage with communities for continuous growth.</p>

<p><img src="/img/2023/2023-10-05-wda-session4.png" alt="Self Assessment" /></p>

<h2 id="impact-of-mentorship">Impact of Mentorship</h2>

<p>I had the privilege of being mentored by Madona Wambua, an accomplished author, keynote speaker, and Android lead engineer. With her extensive background, including being a Google Developer Expert for Android and a GDG NYC Lead, Madona provided unparalleled guidance throughout the course. She hosts “Tech Talks with Madona” and is keen on sharing her wealth of Android knowledge. Our mentorship sessions started with getting to know each other and defining the objectives I wanted to achieve during the program. Under her guidance, I honed my presentation skills and refined my topics. Her mentorship was a cornerstone of my learning experience, and I couldn’t be more grateful for her insights and encouragement.</p>

<h2 id="conclusion">Conclusion</h2>

<p>In summary, the North America Women Developer’s Academy has been an enriching experience that offered more than just technical know-how. I had the chance to connect with remarkable women in the field, each contributing invaluable perspectives and insights. This empowering environment has fine-tuned my public speaking abilities and provided me with actionable tools to share knowledge effectively. I’m excited to put these skills to use at upcoming DevFest events hosted by Google Developer Groups (GDG) in Sacramento and Vancouver. This journey has not only equipped me with essential skills but also expanded my professional network, and I eagerly look forward to contributing to the tech community in meaningful ways.</p>

<figcaption>Cover Photo by Farsai Chaikulngamdee on Unsplash</figcaption>]]></content><author><name>ccstan99</name></author><summary type="html"><![CDATA[Recently, I had the honor of participating in the North America Women Developer’s Academy (WDA) 2023, facilitated by Women Techmakers and the Google Developer Experts. This six-week virtual program focused on strengthening technical women in various aspects, including skill development and community involvement. As a Women Techmakers Ambassador, my main goal was to improve my technical prsentation skills. The program included weekly workshops, mentorship sessions, and coursework. One of the highlights was crafting a 15-minute presentation under expert guidance, aimed at future speaking events.]]></summary></entry><entry><title type="html">Intro to ML</title><link href="http://localhost:4000/2023/09/07/intro-ml.html" rel="alternate" type="text/html" title="Intro to ML" /><published>2023-09-07T00:00:00-07:00</published><updated>2023-09-07T00:00:00-07:00</updated><id>http://localhost:4000/2023/09/07/intro-ml</id><content type="html" xml:base="http://localhost:4000/2023/09/07/intro-ml.html"><![CDATA[<p>I had the honor of co-hosting an Introduction to to Machine Learning (ML) tutorial with Phillipa Burgess, host of Muse and Metrics podcast as well as a fellow Women Techmakers Ambassador. We begin by discussing what ML is and how it differs from traditional programming. Next, we delve into a typical ML workflow that starts with data preparation. After our data is ready, we train a model and evaluate its performance. Lastly, we discuss next steps and free resources to help you continue learning.</p>

<p><img src="/img/2023/2023-09-07-intro-ml-welcome.png" alt="Welcome" /></p>

<h2 id="what-is-machine-learning">What is Machine Learning?</h2>

<h3 id="traditional-programming">Traditional Programming</h3>

<p>In traditional programming, you write explicit rules in code. Take a program that converts temperature from Celsius to Fahrenheit as an example. You input the temperature in Celsius, and the program uses a predefined formula to output the temperature in Fahrenheit.</p>

<h3 id="machine-learning">Machine Learning</h3>

<p>ML, however, works differently. Instead of giving the program a formula, you provide it with examples—pairs of input and output data. The algorithm then goes through the data to find patterns, learning to make predictions on its own. For example, you could provide a bunch of temperatures in Celsius along with their Fahrenheit equivalents, and the model would learn the conversion rule by itself.</p>

<p>This approach is powerful for complex tasks. Consider image recognition: it would be difficult to define explicit rules to determine if a photo contains a cat. But with ML, you can train a model on numerous examples of photos with and without cats, and the algorithm will figure out how to identify them.</p>

<p>Language processing benefits similarly from ML. Instead of feeding a program exhaustive lists of vocabulary and grammar rules, you can train a model on well-written text, allowing it to learn the language’s structure and usage patterns.</p>

<h2 id="data-in-machine-learning">Data in Machine Learning</h2>

<h3 id="understanding-your-data">Understanding Your Data</h3>

<p>Before we get started, it’s crucial to understand your data. Ask questions like:</p>

<ul>
  <li>Where does the data come from?</li>
  <li>What type of data is it—images, numbers, text?</li>
  <li>What questions can the data answer?</li>
</ul>

<p>For this tutorial, we’ll use data about penguins from three specific islands in the Palmer Archipelago. The dataset contains tabular information like bill depth, flipper length, body mass, and sex for each penguin.</p>

<p><img src="/img/2023/2023-09-07-intro-ml-data-explore.png" alt="Data Explore" /></p>

<h3 id="data-preparation">Data Preparation</h3>

<p>Preparing your data is often the most time-consuming part of an ML project. In our case, we’ll use features like bill depth and flipper length as input for our model. First, check for missing data and decide how to handle it. Data needs to be numerical for the algorithm to understand it. Also, for our supervised learning model, the output will be the type of penguin—Adelie, Gentoo, or Chinstrap, encoded numerically as 0, 1, or 2, respectively.</p>

<p>Then, we split the data into a training set and a testing set, often using an 80-20 split. Training on all the data can lead to biased results; it’s crucial to reserve a random sample for evaluation.</p>

<h2 id="models-and-algorithms-in-machine-learning">Models and Algorithms in Machine Learning</h2>

<p><strong>Decision Tree</strong> is a simple yet effective algorithm for beginners. Think of it like a flowchart that makes decisions based on the input features. For example, if a penguin’s bill length is less than 44 mm, it’s most likely an Adelie. The model learns these rules during the training phase.</p>

<p><img src="/img/2023/2023-09-07-intro-ml-tree.png" alt="Decision Tree" /></p>

<p><strong>Decision Forest</strong> is a slightly more advanced algorithm, which employs multiple Decision Trees for better accuracy. Each tree in the forest is trained on different subsets of the data, making the ensemble of trees more reliable and accurate than a single tree.</p>

<p><img src="/img/2023/2023-09-07-intro-ml-forest.png" alt="Decision Forest" /></p>

<p>The good news is that the mathematical and coding aspects of Decision Trees and Forests are mostly handled by existing libraries, letting you focus on the data and the problem at hand. As you delve deeper into ML, you’ll find that a strong foundation is crucial for understanding more complex algorithms and techniques.</p>

<p>Here are links to the <a href="https://bit.ly/WTM23_introML">Google Colab Notebook</a> detailed instructions and the <a href="https://www.youtube.com/watch?v=stgiAM8pTq8&amp;t">YouTube video</a> with the complete tutorial. This was adapted based on the tutorial developed for the 2022 Women in Machine Learning (WiML) Conference by Michelle Carney and Soo Sung from the Tensorflow team.</p>

<h2 id="learning-resources">Learning Resources</h2>

<p>The fun doesn’t have to stop here! There are a TON of free, online resources to help you learn ML and get started with Generative AI!</p>

<ul>
  <li><a href="https://www.deeplearning.ai/short-courses/">DeepLearning.ai</a> series of 1-hour short courses to learn generative AI</li>
  <li><a href="https://www.cloudskillsboost.google/journeys/118">Introduction to Generative AI</a> earn badges while following a learning path with videos &amp; exercises</li>
  <li><a href="https://developers.google.com/machine-learning/crash-course">ML Crash Course</a> Google’s fast-paced, practical introduction to machine learning.</li>
  <li><a href="https://www.fast.ai/">fast.ai</a> if you already have some coding background, this is a practical guide to dive into deep learning.</li>
  <li><a href="https://www.kaggle.com/competitions">Kaggle Competitions</a>, If you’re ready to dive in and start coding, check out the “competitions” on Kaggle! It’s a great way to apply what you’ve learned with a community of other learners.</li>
  <li><a href="https://simplemlforsheets.com/tutorial.html">SimpleML in Google sheets</a> for a no-code way to get started with ML.</li>
  <li><a href="https://goo.gle/made-with-tfjs">Made with TFJS</a> youtube series that highlight awesome projects made for the web!</li>
</ul>]]></content><author><name>ccstan99</name></author><summary type="html"><![CDATA[I had the honor of co-hosting an Introduction to to Machine Learning (ML) tutorial with Phillipa Burgess, host of Muse and Metrics podcast as well as a fellow Women Techmakers Ambassador. We begin by discussing what ML is and how it differs from traditional programming. Next, we delve into a typical ML workflow that starts with data preparation. After our data is ready, we train a model and evaluate its performance. Lastly, we discuss next steps and free resources to help you continue learning.]]></summary></entry><entry><title type="html">Chatbot with Your Data</title><link href="http://localhost:4000/2023/07/15/chatbot.html" rel="alternate" type="text/html" title="Chatbot with Your Data" /><published>2023-07-15T00:00:00-07:00</published><updated>2023-07-15T00:00:00-07:00</updated><id>http://localhost:4000/2023/07/15/chatbot</id><content type="html" xml:base="http://localhost:4000/2023/07/15/chatbot.html"><![CDATA[<ul>
  <li>How do you use LLMs to create chatbots to answer questions for your domain?</li>
  <li>How do you keep the knowledge up-to-date after the model has already been trained?</li>
  <li>How do you ensure generated answers are accurate and avoid hallucinations?</li>
</ul>

<p>Those are some common questions I’ve seen floating around. Unless you’ve been living under a rock, you’re probably aware that ChatGPT, the large language model (LLM) from OpenAI released last November, has taken the world by storm. It’s created excitement but also raised alarm as powerful AIs on the horizon no longer seems as far-fetched science fiction. As such, the group that I’ve been working with to curate quality answers to AI Safety and Alignment questions has been getting an influx of attention and volunteers. In fact, the entire field has seen a flurry of activity.</p>

<h2 id="ai-safety--alignment-chatbot">AI Safety &amp; Alignment Chatbot</h2>

<p>Several months ago <a href="https://www.lesswrong.com/posts/SLRLuiuDykfTdmesK/speed-running-everyone-through-the-bad-alignement-bingo">bounty was placed on LessWrong</a> for a conversational agent educating people on the different approaches to AI Safety and Alignment. Since I’ve been swamped with other projects, I only had a couple days to put together a quick prototype. Fortunately, many of the components needed for the project are related to previous work I’ve already done with extractive question answering:</p>

<ol>
  <li>Processing, chunking, and embedding the alignment research dataset</li>
  <li>Using semantic search to retrieve relevant chunks</li>
  <li>Answering the questions based on the chunk</li>
</ol>

<h2 id="chatbot-with-chatgpt">Chatbot with ChatGPT</h2>

<p>Extracting an answer from a chunk of text is slow and the short few-word answer always felt unsatisfying. On March 1, OpenAI made ChatGPT available to programmers using the <code class="language-plaintext highlighter-rouge">gpt-3.5-turbo</code> model through their <a href="https://platform.openai.com/docs/guides/chat">cloud based API</a>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># TODO code for chat completion, model, temperature, context, chat history messages
</span><span class="kn">import</span> <span class="nn">openai</span>

<span class="n">openai</span><span class="p">.</span><span class="n">ChatCompletion</span><span class="p">.</span><span class="n">create</span><span class="p">(</span>
  <span class="n">model</span><span class="o">=</span><span class="s">"gpt-3.5-turbo"</span><span class="p">,</span>
  <span class="n">messages</span><span class="o">=</span><span class="p">[</span>
        <span class="p">{</span><span class="s">"role"</span><span class="p">:</span> <span class="s">"system"</span><span class="p">,</span> <span class="s">"content"</span><span class="p">:</span> <span class="s">"You are a helpful assistant."</span><span class="p">},</span>
        <span class="p">{</span><span class="s">"role"</span><span class="p">:</span> <span class="s">"user"</span><span class="p">,</span> <span class="s">"content"</span><span class="p">:</span> <span class="s">"What is AI Safety?"</span><span class="p">},</span>
    <span class="p">]</span>
<span class="p">)</span>
</code></pre></div></div>

<h2 id="collaboration">Collaboration</h2>

<p>We’ve been fortunate collaborate with other teams who also submitted prototypes and are dedicated to scaling AI safety and alignment education. Developers from the Stampy team also made incredible contributions to clean up our underlying dataset, which serves as the knowledge base, and also ensure we had proper infrastructure resources to get deployed. It’s been great learning from everyone and leveraging the best aspects from each project. Some of the notable features from other projects include:</p>

<ul>
  <li>Detailed citations of sources with a streaming GUI</li>
  <li>Using langchain to rephrase standalone improving conversational capabilities</li>
  <li>Suggesting followup questions to keep the conversation flowing</li>
</ul>

<p>There are definitely other areas of improvement we’re still working on:</p>

<ul>
  <li>Cleaning up the underlying dataset</li>
  <li>Prompt engineering to ensure accuracy and appropriate tone</li>
  <li>More thorough benchmarked testing, UX research, UI design</li>
  <li>Customizing answer generation options based on user’s level and needs</li>
  <li>Experimenting with other document splitting, vector DBs, embeddings &amp; retrieval, LLMs</li>
</ul>

<p>Together look forward to building a better product that can help answer questions based on the rapidly growing body of alignment research literature. If you’re interested in helping, please join us on <a href="https://discord.gg/cSVG2FdX">Rob Mile’s Discord</a>. Feel free to see our current progress on GitHub for the <a href="https://github.com/stampyAI/stampy-chat">chatbot</a> and the <a href="https://github.com/stampyAI/alignment-research-dataset">dataset</a>.</p>

<p>As I’ve been conducting additional research, I’ll continue adding more resources on LangChain, prompt engineering, and fine-tuning a SBERT model below.</p>

<h2 id="prompt-engineering">Prompt Engineering</h2>

<p>As LLMs are getting better at understanding language and generalizing knowledge, the need to train or fine-tune models may be replaced with a need to understand how to interact or prompt LLMs to yield the best results. Below are some resources and guidelines for doing so:</p>

<ul>
  <li><a href="https://github.com/openai/openai-cookbook/blob/main/techniques_to_improve_reliability.md#how-to-improve-reliability-on-complex-tasks">OpenAI Cookbook</a> along with <a href="https://learn.deeplearning.ai/chatgpt-prompt-eng/">DeepLearning.AI on Coursera</a> 1-hour introduction</li>
  <li><a href="https://github.com/dair-ai/Prompt-Engineering-Guide">DAIR.AI</a> has good references to research literature</li>
  <li><a href="https://learnprompting.org/docs/additional">LearnPrompting.org</a> provides basic introduction</li>
  <li><a href="https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/">Lilian Weng’s Blog</a></li>
</ul>

<h2 id="langchain">LangChain</h2>

<p>LangChain is a valuable library that makes it easier to work with LLM from ingesting data by splitting up text and offering abstractions for different vectorstores, embedding models, prompt templates and text generation LLMs. It also handles conversational memory and chaining multiple calls to the LLMs, treating them like agents:</p>

<ul>
  <li><a href="https://python.langchain.com/en/latest/">LangChain Documentation</a></li>
  <li><a href="https://github.com/hwchase17/langchain">LangChain GitHub Repo</a> includes examples</li>
  <li><a href="https://learn.deeplearning.ai/langchain/">DeepLearning.AI on Coursera</a> for 1-hour introduction</li>
</ul>

<h2 id="general-resources">General Resources</h2>

<ul>
  <li><a href="https://arxiv.org/abs/2005.11401">Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks</a></li>
  <li><a href="https://platform.openai.com/docs/guides/chat">ChatGPT</a></li>
  <li><a href="https://github.com/hwchase17/langchain">LangChain</a></li>
  <li><a href="https://www.lesswrong.com/posts/SLRLuiuDykfTdmesK/speed-running-everyone-through-the-bad-alignement-bingo">LessWrong Bounty</a></li>
</ul>

<figcaption>Cover Photo by Mike Lewis HeadSmart Media on Unsplash</figcaption>]]></content><author><name>ccstan99</name></author><summary type="html"><![CDATA[How do you use LLMs to create chatbots to answer questions for your domain? How do you keep the knowledge up-to-date after the model has already been trained? How do you ensure generated answers are accurate and avoid hallucinations?]]></summary></entry><entry><title type="html">LLM Mechanistic Interpretability</title><link href="http://localhost:4000/2023/06/30/mech-interpret.html" rel="alternate" type="text/html" title="LLM Mechanistic Interpretability" /><published>2023-06-30T00:00:00-07:00</published><updated>2023-06-30T00:00:00-07:00</updated><id>http://localhost:4000/2023/06/30/mech-interpret</id><content type="html" xml:base="http://localhost:4000/2023/06/30/mech-interpret.html"><![CDATA[<p>Mechanistic interpretability of large language models (LLMs) is a detailed exploration of the inner workings of Transformer-based model. It dissects and reverse engineers individual components like attention heads, layers, and neurons to understand their specific roles in model decisions. This is a new and exciting field that sits at the intersection of my life experiences. As an undergrad, I studied linguistics and computer science, particularly Natural Language Processing (NLP) and human languages in general. Homeschooling brought me into the education space. This gave me the opportunity to explore language acquisition through immersion and delve into effective pedagogical methods. I initially stumbled into the field while reviewing two papers for a work project:</p>

<ul>
  <li><a href="https://arxiv.org/abs/2301.05217">Progress measures for grokking via mechanistic interpretability</a></li>
  <li><a href="https://arxiv.org/abs/2303.08112">Eliciting Latent Predictions from Transformers with the Tuned Lens</a></li>
</ul>

<p>As I familiarize myself with the field, I am captivated by the potential it holds for linguistics. Theoretical linguists such as Noam Chomsky’s criticize that Large Language Models (LLMs) merely find statistical patterns in data and lack true understanding of human languages. Nevertheless, models trained on vast amounts of data have deciphered remarkable statistical relationships that could provide valuable insights for research in syntax and semantics. Furthermore, potential applications extend to phonetics and phonology, especially when considering how Whisper models effectively use attention patterns in spectrograms.</p>

<h2 id="mechanistical-interpretability--transformerlens">Mechanistical Interpretability + TransformerLens</h2>

<p>When I first encountered Anthropic’s Mathematical Framework, I found it puzzling yet intriguing. Fundamentally, why WOULDN’t anyone be interested in HOW and WHY these LLMs work? Would understanding these help us understand how humans understand language? I’d imagine many neuroscientists wished they could probe a living human brain and in real-time see what’s happening inside these neurons. Mechanistic interpretability tries to do exactly that with the Transformers of LLMs! Here are a few helpful resources to get orientated:</p>

<ul>
  <li><a href="https://youtu.be/ll0oduwDEwI">Mechanistic Interpretability: Getting Started</a> - Catherine Olsson’s talk at Cohere</li>
  <li><a href="https://www.neelnanda.io/mechanistic-interpretability/getting-started">Concrete Steps to Get Started in Transformer Mechanistic Interpretability</a></li>
  <li><a href="https://transformer-circuits.pub/">Transformer Circuits</a></li>
  <li><a href="https://transformer-circuits.pub/2021/framework/index.html">A Mathematical Framework for Transformer Circuits</a></li>
  <li><a href="https://www.youtube.com/playlist?list=PLoyGOS2WIonajhAVqKUgEMNmeq3nEeM51">Anthropic Videos</a> and <a href="https://transformer-circuits.pub/">Transformer Circuits</a> blog</li>
</ul>

<p>TransformerLens is a tool designed to elucidate the inner workings of Transformer-based models like BERT or GPT-2. It facilitates the exploration of model components and their interactions, aiding in debugging, improving, and gaining insights from these complex models. I joined a small study group learning to use TransformerLens. It served as an excellent excuse to dig into the GitHub repo and get some hands on experience working through a tutorial.</p>

<ul>
  <li><a href="https://github.com/neelnanda-io/TransformerLens">TransformerLens Repo</a></li>
  <li><a href="https://transformerlens-intro.streamlit.app/">TransformerLens Tutorial</a></li>
</ul>

<h2 id="eliciting-latent-knowledge">Eliciting Latent Knowledge</h2>

<p>I’ve been reasing through other fascinating papers trying to figure out what LLMs have “learned” and what they “know” by looking at internal activations or embeddings in an unsupervised manner. I’ll park some papers I’ve been reading and will come back to synthesize these as part of future projects:</p>

<ul>
  <li><a href="https://arxiv.org/abs/2212.03827">Discovering Latent Knowledge in Language Models Without Supervision</a></li>
  <li><a href="https://arxiv.org/abs/2207.05221">Language Models (Mostly) Know What They Know</a></li>
  <li><a href="https://arxiv.org/abs/2008.02275">Aligning AI With Shared Human Values</a></li>
  <li><a href="https://arxiv.org/abs/2110.13136">What Would Jiminy Cricket Do? Towards Agents That Behave Morally</a></li>
  <li><a href="https://arxiv.org/abs/2304.03279">Do the Rewards Justify the Means? Measuring Trade-Offs Between Rewards and Ethical Behavior in the MACHIAVELLI Benchmark</a></li>
  <li><a href="https://arxiv.org/abs/1909.05398">Interactive Fiction Games: A Colossal Adventure</a></li>
  <li><a href="https://arxiv.org/abs/2010.02903">Keep CALM and Explore: Language Models for Action Generation in Text-based Game.</a></li>
</ul>]]></content><author><name>ccstan99</name></author><summary type="html"><![CDATA[Mechanistic interpretability of large language models (LLMs) is a detailed exploration of the inner workings of Transformer-based model. It dissects and reverse engineers individual components like attention heads, layers, and neurons to understand their specific roles in model decisions. This is a new and exciting field that sits at the intersection of my life experiences. As an undergrad, I studied linguistics and computer science, particularly Natural Language Processing (NLP) and human languages in general. Homeschooling brought me into the education space. This gave me the opportunity to explore language acquisition through immersion and delve into effective pedagogical methods. I initially stumbled into the field while reviewing two papers for a work project:]]></summary></entry><entry><title type="html">Demystifying ChatGPT + LLMs</title><link href="http://localhost:4000/2023/05/24/chatgpt-llms.html" rel="alternate" type="text/html" title="Demystifying ChatGPT + LLMs" /><published>2023-05-24T00:00:00-07:00</published><updated>2023-05-24T00:00:00-07:00</updated><id>http://localhost:4000/2023/05/24/chatgpt-llms</id><content type="html" xml:base="http://localhost:4000/2023/05/24/chatgpt-llms.html"><![CDATA[<p>Welcome to the world of ChatGPT and LLMs filled with alphabet soup jargon. We’ll look at language models, how they got so large, and think about how to deal with all this AI buzz.</p>

<h2 id="background-in-natural-language-processing-nlp">Background in Natural Language Processing (NLP)</h2>

<p>Language models live in the field of natural language processing, The ultimate dream, the holy grail, is to talk with computers just like talking with any other person and have it completely understand you. No need to learn computer languages. They can speak ours. Originally, linguists would painstakingly create “expert” systems, hand-coding  grammar rules and all the vocabulary. Unfortunately, the end results were mediocre, at best.</p>

<p><img src="/img/2023/2023-05-24-llms-stats.png" alt="Statistics in LLMs" /></p>
<figcaption>Photo by Towfiqu Barbhuiya on Unsplash</figcaption>

<p>Towards the late 90s, statistical methods were used. There’s a famous quote, “You shall know a word by the company it keeps.” That simple idea was profound. If you start counting words and looking at what other words tend to occur with it, you’ll end up learning a lot about the language itself. All those relationships make up the language model. Think back to when you were first learning your native language. As a child, you were immersed with sounds, words, and sentences of your language. Now, you have intuition of what sounds right or what’s off, even if you don’t know why. You’ve internalized all the statistics for your own language model.</p>

<h2 id="rise-of-transformers">Rise of Transformers</h2>

<p>Transformers are a special kind of neural network introduced by Google in 2017.</p>

<p>Before that, language models were painfully slow and forgetful. Imagine a sweet old granny struggling to understand words one by one and getting confused by long sentences. So, if you had tried to make models bigger, trained on more data, it didn’t matter.</p>

<p><img src="/img/2023/2023-05-24-llms-superhero.png" alt="Transformers are Superheroes" /></p>
<figcaption>Photo from Everything Everywhere All at Once (2022)</figcaption>

<p>Things didn’t really improve much until Transformers came along with attention superpowers. Now, models could look at everything, all at once. Long-term memory? No problem. Now, we can train on all of Wikipedia and piles and piles of books. The models kept learning and improving. Turns out, neural networks are extremely data hungry. They need tons of it to learn. So people went out and scraped everything they could find on the web: blogs, tweets, code, whatever was out there.</p>

<p>Another innovation: Transformers could process data in parallel. Otherwise, it’s like one checkout stand serving 100 customers one at a time, sequentially. Instead, Transformers use 100 checkout stands to serve all 100 customers at the same time in parallel. So models got bigger, running faster, training longer on more data, and performance kept getting better!</p>

<p>Thus began the rise of large language models. Size is measured by the number of parameters or neurons. Today, to be large, a language model must have at least 1 billion neurons. They’re not the same, but for reference, the human brain has around 85 billion. And all the large language models today are some variant of Transformers, which completely revolutionized AI beyond just language!</p>

<h2 id="generative-pre-trained-transformers-gpt">Generative pre-trained transformers (GPT)</h2>

<p>Generative pre-trained transformers or GPT shine at generating text.</p>

<p>They are trained for next word prediction. It’s like a play the game. You grab a book, pick a sentence, and show the model the beginning of the sentence. It tries to guess the next word in the sentence. You show it the actual next word. Hmm, if it’s wrong, let’s update the neurons to do better the next time. Pick another sentence. Guess another word and update. Then repeat until the model gets really good at guessing the next words. Starting with “Twinkle Twinkle Little…” the next word is most likely “Star.” Maybe feels like a sophisticated auto-complete. Think about when you’re talking with someone and you “complete each other’s sentences.” It’s often a sign of deep mutual understanding. Imagine a computer doing the same.</p>

<p><img src="/img/2023/2023-05-24-llms-training.jpg" alt="Pre-Training LLMs" /></p>

<p>When it comes to P in Pre-training we need to look to the past. A variety of different models would be trained as specialists: one for answering questions, another for classifying things, or for translation. But GPT is a generalist, pre-trained to understand human languages in general, which can be quickly fine-tuned on top of the pre-trained base.</p>

<p>GPT was created by OpenAI. The original, GPT-1, was introduced in 2018, jumping in after Google’s transformers. The next year, GPT-2 was 10 times larger. The year after that, GPT-3 was 100 times larger. By then, it was almost impossible to tell what’s generated and what’s not. As for GPT-4 that just came out? It’s a secret. Keep in mind, these models are huge. It costs millions of dollars to train on a slew of computers over a period of months. It’s not feasible for individuals or even academic researchers to train anything like this. You need those deep pockets.</p>

<h2 id="chatgpt">ChatGPT</h2>

<p>Then along came ChatGPT. Frankly, many working in the field were baffled, “Why is this going viral now? It’s just GPT-3.5, with minor tweaks to the base model released three years ago!”</p>

<p>The secret sauce was reinforcement learning from human feedback. Remember, GPT was trained to predict the next word given the start of a sentence. That’s great for learning the language, but really, that’s not as helpful for the typical end user. When you talk to people, you rarely begin a sentence and then expect them to complete it. Instead, you’re more likely to tell them to do something or maybe ask a question.</p>

<p>So GPT-3 was fine-tuned to respond to instructions. They got lots of sample instructions along with what’s expected. If you see “Prepare a report,” the output should indicate what a report looks like. For “Give me a summary,” the output should indicate what a summary looks like.</p>

<p><img src="/img/2023/2023-05-24-llms-instruct.jpg" alt="ChatGPT was Fine-tuned on Instructions" /></p>

<p>Next, it was also fine-tuned on sample back-and-forth conversations to learn how dialogues work. These extra fine-tuning steps were quick and cheap compared to pre-training the original, which took months and millions. It managed to bring out some innate abilities hidden in the base model. But suddenly, following instructions and carrying conversations made it extremely helpful and eerily “human.”</p>

<h2 id="on-the-horizon">On the Horizon</h2>

<p>That us up to late last year. Now, things are moving even faster since then. Let me point out a few items on the horizon to keep an eye on.</p>

<dl>
  <dt>Multi-modality</dt>
  <dd>Language models deal mainly with text. Multi-modality allows them to use audio, images, and videos to understand the world. And the better to see you, to hear you, and to interact with you.</dd>
  <dt>Open-Source</dt>
  <dd>Just a few weeks ago, Meta released an open-sourced large language model that can run on personal computers. That led to a flurry of activity. Researchers are now creating much smaller and cheaper models that are still powerful.</dd>
  <dt>Agents</dt>
  <dd>Language models can generate text for a plan. Now, they can also call agents, which are programs to execute that plan. “Plan a trip to Tokyo.” It goes to compare prices, book flights, find lodging. You just show up and enjoy. But if AI automatically connects to agents that can change things in the real world with consequences, we must stop and think, “What could possibly go wrong?!”</dd>
</dl>

<h2 id="hype-or-reality">Hype or Reality?</h2>

<p>Is this all hype? Or is the world really changing? I started working in tech during the dot-com era. The gold rush euphoria feels suspiciously familiar. But there’s definitely a fundamental paradigm shift that’s both thrilling but a tad worrying.</p>

<p>Personally, I use large language models every day. They’re great for mundane tasks like proofreading documents, drafting emails, or generating code snippets. Search is really handy. Information is synthesized and summarized for your specific case. But I only use AI as a tool to speed up my normal workflow. I still double-check the output since it’s not all sunshine and rainbows.</p>

<p>You must understand the limitations. Hallucinations are a big problem. That’s a technical term when the output is just flat out wrong but sounds really convincing and confident. A dangerous combination. Essentially, AI is a master B.S.er, but plenty of humans are too. It’s just regurgitating what’s learned from its training data, which includes lots of toxic and biased stuff too. So what’s the key takeaway?</p>

<h2 id="conclusion">Conclusion</h2>

<p>We’re standing at the dawn of this new era shaped by AI. In order to survive, you’ll have to embrace AI in some way. No one wants to be the dinosaur. Sometimes, it feels like we’re blindly rushing into this awe-inspiring yet potentially treacherous territory. AI is a tool that holds immense power, but it’s far from perfect or even safe. As the saying goes, “Trust but verify.” We need to keep humans in the loop. My hope is that we can be guided by wisdom, empathy, and a commitment to embrace the power of AI responsibly.</p>

<p><img src="/img/2023/2023-05-24-llms-embrace.png" alt="Embrace AI Responsibly" /></p>
<figcaption>Photo by Diego PH, Cover by Towfiqu barbhuiya on Unsplash</figcaption>]]></content><author><name>ccstan99</name></author><summary type="html"><![CDATA[Welcome to the world of ChatGPT and LLMs filled with alphabet soup jargon. We’ll look at language models, how they got so large, and think about how to deal with all this AI buzz.]]></summary></entry><entry><title type="html">Google I/O 2023</title><link href="http://localhost:4000/2023/05/10/google-io.html" rel="alternate" type="text/html" title="Google I/O 2023" /><published>2023-05-10T00:00:00-07:00</published><updated>2023-05-10T00:00:00-07:00</updated><id>http://localhost:4000/2023/05/10/google-io</id><content type="html" xml:base="http://localhost:4000/2023/05/10/google-io.html"><![CDATA[<p><a href="https://io.google/2023/">Google I/O 2023</a> proved to be a memorable experience in so many ways!</p>

<h2 id="pre-reception">Pre-Reception</h2>

<p>The event kicked off with the Women Techmakers Ambassadors at the pre-reception on Tuesday evening. It was such an exciting moment to finally meet and connect with Creatives in Tech in person. We were buzzing with anticipation, eager to learn from each other and soak up all the knowledge and inspiration that awaited us.</p>

<p><img src="/img/2023/2023-05-10-io-reception.jpg" alt="evening reception" /></p>

<h2 id="keynote-at-shoreline">Keynote at Shoreline</h2>

<p>One of the highlights of the event was undoubtedly the I/O keynote addresses. It was wonderful to witness Google’s announcements firsthand and watch the impressive AI/ML demos. The entire event was incredibly well-organized, right from the convenient shuttle services to the delicious breakfast and lunch options. And to our surprise, we were even provided with caps, sweatshirts, sunscreen, rain ponchos, and hand warmers - they truly had us covered for any unexpected weather or situation.</p>

<p><img src="/img/2023/2023-05-10-io-keynote.jpg" alt="morning keynotes" /></p>

<h2 id="breakouts-at-bay-view">Breakouts at Bay View</h2>

<p>After the keynote, we had the chance to attend breakout sessions at Google’s new Bayview campus. It was an opportunity to delve deeper into topics like women in leadership and AI/ML. The sessions were informative, engaging, and filled with valuable insights. We couldn’t resist exploring the beautiful campus and taking advantage of the bike trails. It was a refreshing way to unwind and enjoy the surroundings.</p>

<p><img src="/img/2023/2023-05-10-io-bayview.jpg" alt="afternoon breakouts" /></p>

<p>I had such a fantastic time at Google I/O 2023 and highly recommend attending the event in the future. The atmosphere was fun-filled, the knowledge-sharing was inspiring, and the connections made were invaluable. Can’t wait for next time!</p>

<p>Until then, keep exploring, learning, and embracing the exciting world of technology!</p>]]></content><author><name>ccstan99</name></author><summary type="html"><![CDATA[Google I/O 2023 proved to be a memorable experience in so many ways!]]></summary></entry><entry><title type="html">Dare to be Creative in Tech</title><link href="http://localhost:4000/2023/03/22/wtm-iwd.html" rel="alternate" type="text/html" title="Dare to be Creative in Tech" /><published>2023-03-22T00:00:00-07:00</published><updated>2023-03-22T00:00:00-07:00</updated><id>http://localhost:4000/2023/03/22/wtm-iwd</id><content type="html" xml:base="http://localhost:4000/2023/03/22/wtm-iwd.html"><![CDATA[<p>Are you a woman in tech? Do you want to hear from other creative and talented women in the industry? Look no further than the Women Techmakers Ambassador community, Creatives in Tech! On March 22nd, we celebrated International Women’s Day by hosting a virtual event that highlighted the experiences of creative women in tech.</p>

<p><img src="/img/2023/2023-03-22-iwd-promo.jpg" alt="promo" /></p>

<h2 id="our-event">Our Event</h2>

<p>The 6-hour event featured keynote speeches, panel discussions, and even a job board filled with potential job opportunities for creative tech roles.</p>

<dl>
  <dt>Opening: Dare to Bring Diversity to Web 3.0</dt>
  <dd>(10 am PDT / 12pm CDT / 1pm EDT)</dd>
  <dd>Keynote Speaker: Tina Bonner, CEO &amp; Founder Black in Meta</dd>
  <dt>Embracing Creativity in Tech</dt>
  <dd>(11 am PDT / 1pm CDT / 2pm EDT)</dd>
  <dd>Panelists: Kavitha Bangalore and Raj Sree</dd>
  <dd>Moderator: ChengCheng Tan</dd>
  <dt>Break and Job Jam!</dt>
  <dd>(12pm PDT / 2pm CDT / 3pm EDT)</dd>
  <dt>Creative Tech Corner</dt>
  <dd>(1pm PDT / 3pm CDT / 4pm EDT)</dd>
  <dd>Speakers: Vaishnavi Venkata Subramaniam and Ashley Clayton</dd>
  <dt>The Daring Mindset: Design Thinking</dt>
  <dd>(2pm PDT / 4pm CDT / 5pm EDT)</dd>
  <dd>Panelists: Kaylyn Hill and Michelle Ng</dd>
  <dd>Moderator: ChengCheng Tan</dd>
  <dt>How Daring to be Non-Traditional Secured Me a Job</dt>
  <dd>(3pm PDT / 5pm CDT / 6pm EDT)</dd>
  <dd>Keynote Speaker: Alaa Shahin, UX Designer at Univ of Michigan</dd>
</dl>

<p>We had an amazing turnout, with over 140 registrations on <a href="https://www.eventbrite.com/e/dare-to-be-creative-in-tech-tickets-560933706817">EventBrite</a>. <a href="https://gatheround.com/">Gatheround</a>, as our platform, was perfect for adding a creative touch and allowing for an interactive experience.</p>

<h2 id="our-team">Our Team</h2>

<p>It was an immense honor to befriend so many smart and talented Women Techmaker Ambassadors. Our team of 12 volunteers and 9 speakers worked together to create a comprehensive plan that included a general run of show and weekly meetings starting in mid-January. Kaylyn spearheaded the event, guided us withe her vision, and provided extensive planning documents to keep everything on track. Michelle, our wonderful head of marketing, put together a social media toolkit and recruited backend volunteers. I offered input from the early stages and became more active as an organizer towards the end of February, taking time off work to ensure that everything went smoothly. All the volunteers and speakers actively contributed ideas and ultimately formed a sisterly bond.</p>

<p><img src="/img/2023/2023-03-22-iwd-photobooth.png" alt="photobooth" /></p>

<h2 id="join-our-community">Join Our Community</h2>

<p>Overall, it was an incredibly experience and we hope to continue building our community of talented women in tech. If you’re interested in joining us or attending future events, be sure to follow us on <a href="https://www.linkedin.com/company/creatives-in-tech/">LinkedIn</a> and keep an eye out for our next event announcement. We hope to see you there! ⚡️</p>

<p>This event was generously supported by <a href="https://developers.google.com/womentechmakers">Google Women Techmakers</a>, <a href="https://www.mylivestack.com/">WeTransact.Live</a>, and <a href="https://gatheround.com/">Gatheround</a>.</p>

<figcaption>Cover Photo by Hannah Busing on Unsplash</figcaption>]]></content><author><name>ccstan99</name></author><summary type="html"><![CDATA[Are you a woman in tech? Do you want to hear from other creative and talented women in the industry? Look no further than the Women Techmakers Ambassador community, Creatives in Tech! On March 22nd, we celebrated International Women’s Day by hosting a virtual event that highlighted the experiences of creative women in tech.]]></summary></entry><entry><title type="html">TensorFlow Developer Certification</title><link href="http://localhost:4000/2023/02/13/tensorflow-cert.html" rel="alternate" type="text/html" title="TensorFlow Developer Certification" /><published>2023-02-13T00:00:00-08:00</published><updated>2023-02-13T00:00:00-08:00</updated><id>http://localhost:4000/2023/02/13/tensorflow-cert</id><content type="html" xml:base="http://localhost:4000/2023/02/13/tensorflow-cert.html"><![CDATA[<p>Look what I got! I hope return to fill in more details of how I prepared for the exam and some helpful resources. Overall, this was an excellent learning experience that helped me upskill for Artificial Intelligence, Machine Learning, and Deep Learning in a focused manner.</p>

<p><a href="https://www.credential.net/dd29cf54-be96-4380-8b4c-bc4c5971c781#gs.z3o0gx"><img src="/img/2023/2023-02-13-tensorflow-cert.png" alt="TensorFlow Developer Certificate" /></a></p>

<p>For starters, review the candidate handbook very carefully. The DeepLearning.AI on Coursera lays a strong foundation but you’ll need additional hands on practice as well. Be sure you’re comfortable with these topics:</p>

<h2 id="1-introduction-to-tensorflow">1. Introduction to TensorFlow</h2>

<ul>
  <li>Learn best practices for using TensorFlow, a popular open-source machine learning framework</li>
  <li>Build a basic neural network in TensorFlow</li>
  <li>Train a neural network for a computer vision application</li>
  <li>Understand how to use convolutions to improve your neural network</li>
</ul>

<h2 id="2-convolutional-neural-networks-in-tensorflow">2. Convolutional Neural Networks in TensorFlow</h2>

<ul>
  <li>Handle real-world image data</li>
  <li>Plot loss and accuracy</li>
  <li>Explore strategies to prevent overfitting, including augmentation and dropout</li>
  <li>Learn transfer learning and how learned features can be extracted from models</li>
</ul>

<h2 id="3-natural-language-processing-in-tensorflow">3. Natural Language Processing in TensorFlow</h2>

<ul>
  <li>Build natural language processing systems using TensorFlow</li>
  <li>Process text, including tokenization and representing sentences as vectors</li>
  <li>Apply RNNs, GRUs, and LSTMs in TensorFlow</li>
  <li>Train LSTMs on existing text to create original poetry and more</li>
</ul>

<h2 id="4-sequences-time-series-and-prediction">4. Sequences, Time Series and Prediction</h2>

<ul>
  <li>Solve time series and forecasting problems in TensorFlow</li>
  <li>Prepare data for time series learning using best practices</li>
  <li>Explore how RNNs and ConvNets can be used for predictions</li>
  <li>Build a sunspot prediction model using real-world data</li>
</ul>

<h2 id="miscellaneous-tips">Miscellaneous Tips</h2>

<ul>
  <li>Studied additional topics…</li>
  <li>Used both local GPU + Google colabs</li>
  <li>Kept handy code snippets for TensorBoard, early stopping, checkpoints, etc</li>
</ul>

<h2 id="resources">Resources</h2>

<ul>
  <li><a href="https://www.tensorflow.org/certificate">Review Candidate Handbook</a></li>
  <li><a href="https://www.coursera.org/professional-certificates/tensorflow-in-practice">DeepLearning.AI on Coursera</a></li>
  <li><a href="https://github.com/ageron/handson-ml3">Hands-On ML with Scikit-Learn, Keras, and TensorFlow</a></li>
</ul>]]></content><author><name>ccstan99</name></author><summary type="html"><![CDATA[Look what I got! I hope return to fill in more details of how I prepared for the exam and some helpful resources. Overall, this was an excellent learning experience that helped me upskill for Artificial Intelligence, Machine Learning, and Deep Learning in a focused manner.]]></summary></entry><entry><title type="html">Women Techmakers Ambassador</title><link href="http://localhost:4000/2022/12/07/wtm-ambassador.html" rel="alternate" type="text/html" title="Women Techmakers Ambassador" /><published>2022-12-07T00:00:00-08:00</published><updated>2022-12-07T00:00:00-08:00</updated><id>http://localhost:4000/2022/12/07/wtm-ambassador</id><content type="html" xml:base="http://localhost:4000/2022/12/07/wtm-ambassador.html"><![CDATA[<p>I’m delighted to share that I recently became a Google’s Women Techmakers (WTM) Ambassador, joining a vibrant community of over 1000 women from around the world who are passionate about technology and dedicated to fostering equity and diversity in the tech industry. The onboarding introduced me to the program’s mission, resources, and the many ways in which I can contribute to my community.</p>

<p><img src="/img/2022/2022-12-07-wtm-ambassador.gif" alt="I'm a WTM Ambassador!" /></p>

<p>After working in tech for many years now, I’ve gotten to the “sea of dudes”. Until recently, I’d never been involved with any movements geared towards women in tech. I’ve worked with great guys but I’ve realized that working with other women in tech has such a refreshingly nurturing vibe. Now, I’m wondering: Why didn’t I start sooner?!</p>

<h2 id="notification--onboarding">Notification &amp; Onboarding</h2>

<p>In mid-November, I received a notification that I had been selected as a WTM Ambassador. The application process evaluated past leadership experience, so it was humbling to be recognized as part of this global community of change-makers. The global onboarding was held in early December, then followed by the North American onboarding the next week. During these sessions, the WTM team highlighted the diverse ways in which we can contribute to the community’s growth. From speaking at events and organizing meet-ups to mentoring aspiring individuals and creating valuable resources such as blogs or podcasts, the ambassador role is truly multi-faceted. Google also provides continuing development for technical and applied skills. Together, these set the stage for collaboration and global networking.</p>

<h2 id="international-womens-day">International Women’s Day</h2>

<p>The International Women’s Day (IWD) events from March through April are a highlight for WTM. These annual events serve as a powerful platform to celebrate the achievements of women in tech and inspire future generations. Google offers incentives and support to WTM Ambassadors helping contribute to the success of IWD by organizing events, spreading awareness, while making a meaningful impact.</p>

<p>As I embark on this incredible journey as a Women Techmakers Ambassador, I’m filled with excitement and gratitude. I look forward to leveraging my skills and experiences to support others in tech. The opportunity to be a part of a global network of like-minded individuals and the chance to make a tangible impact in my community are priceless.</p>

<figcaption>Cover Photo by Toa Heftiba on Unsplash</figcaption>]]></content><author><name>ccstan99</name></author><summary type="html"><![CDATA[I’m delighted to share that I recently became a Google’s Women Techmakers (WTM) Ambassador, joining a vibrant community of over 1000 women from around the world who are passionate about technology and dedicated to fostering equity and diversity in the tech industry. The onboarding introduced me to the program’s mission, resources, and the many ways in which I can contribute to my community.]]></summary></entry></feed>