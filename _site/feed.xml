<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2022-08-04T08:45:00-07:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">ccstan99</title><subtitle>ccstan99&apos;s learning journal</subtitle><author><name>ccstan99</name></author><entry><title type="html">Find Duplicates with SBERT</title><link href="http://localhost:4000/2022/06/14/sbert.html" rel="alternate" type="text/html" title="Find Duplicates with SBERT" /><published>2022-06-14T00:00:00-07:00</published><updated>2022-06-14T00:00:00-07:00</updated><id>http://localhost:4000/2022/06/14/sbert</id><content type="html" xml:base="http://localhost:4000/2022/06/14/sbert.html"><![CDATA[<h2 id="finding-duplicates">Finding Duplicates</h2>

<p>I’ve been working on a AGI Safety FAQ project where the questions culled from multiple sources including YouTube video comments and a Discord server. Those that are marked as high interest are then answered and evaluated by community of volunteers. At some point, we realized there’s likely to be quite a number of duplicate or at least semantically very similar questions in the database. The concern is of course that this could be a potentially time-consuming and resource-heavy operation since we’d need to compare every question in the database with every other, resulting in the dreaded O(n<sup>2</sup>).</p>

<h2 id="sentence-bert">Sentence-BERT</h2>

<p>After a bit of research, I found <a href="https://sbert.net/">Sentence-BERT (SBERT)</a> a modification of BERT, but is optimized for generating accurate and useful sentence embeddings. It uses Siamese and triplet network structure to derive embeddings that can be compared efficiently using cosine similarity. This reduces the time for finding the most similar pairs among 10,000 sentences from 65 hours with BERT or RoBERTa down to about 5 seconds, without sacrificing accuracy!</p>

<p>Here are the <a href="/docs/JournalClub%202022-07-27%20SBERT.pdf">slides</a> from the presentation I gave on the <a href="https://arxiv.org/abs/1908.10084">journal paper</a>, which goes into greater depth about the training architecture setup and various methods &amp; datasets for evaluation. It turns outs natural language inference (<a href="https://huggingface.co/datasets/SetFit/mnli">MNLI</a> &amp; SNLI) datasets which are fairly large and indicate entailment, serve as excellent training sets for fine-tuning semantic simiarity tasks. However, training on specific <a href="https://arxiv.org/abs/1708.00055v1">semantic textual similarity (STS-b)</a>] dataset, which are much smaller, boosted performance even further.</p>

<h2 id="pretrained-models">Pretrained Models</h2>

<p>Now, there’s a evergrowing number of <a href="https://sbert.net/docs/pretrained_models.html">pretrained sentence-transformer model checkpoints</a> ranked by size, speed, and other performance metrics. A model can be initialized by passing it a checkpoint that indicates a combination of both the model architecture plus the specific trained weights. Since our goal was to identify pairs of more similar questions or sentences, we tried several models that performed best on semantic search leaderboards.</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">multi-qa-mpnet-base-dot-v1</code> trained on 315M StackExchange, Yahoo Answers, Google &amp; Bing questions. Scored highest on semantic similarity benchmarks.</li>
  <li><code class="language-plaintext highlighter-rouge">distilbert-base-nli-stsb-quora-ranking</code> trained on 500K Quora duplicate questions.</li>
  <li><code class="language-plaintext highlighter-rouge">all-MiniLM-L6-v2</code> general purpose model 1B+ training pairs. Considered generic fast and good not great quality.</li>
  <li><code class="language-plaintext highlighter-rouge">paraphrases-multi-qa-mpn</code> gave us best results on our dataset ascertained by expert human evaluation.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">sentence</span><span class="o">-</span><span class="n">transformers</span>
<span class="kn">from</span> <span class="nn">sentence_transformers</span> <span class="kn">import</span> <span class="n">SentenceTransformer</span>
<span class="c1"># choose from list of pretrained models at sbert.net/docs/pretrained_models.html
</span><span class="n">checkpoint</span> <span class="o">=</span> <span class="s">"paraphrases-multi-qa-mpn"</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">SentenceTransformer</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="paraphrase-mining">Paraphrase Mining</h2>

<p>The <code class="language-plaintext highlighter-rouge">sentence_tranformers</code> module provides a super-handy <a href="https://sbert.net/examples/applications/paraphrase-mining/README.html#paraphrase-mining"><code class="language-plaintext highlighter-rouge">paraphrase_mining</code></a> utility that returns a list of tuples sorted by descending similarity scores along with the indices of 2 sentences from the original list of input sentences. A score of 1.0 means the 2 sentences are semantically identical, while a score of 0.0 means they are semantically unrelated.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sentence_transformers</span> <span class="kn">import</span> <span class="n">util</span>
<span class="c1"># Single list of sentences - Possible +10,000 of sentences
</span><span class="n">sentences</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">"fulltext"</span><span class="p">].</span><span class="n">values</span><span class="p">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="n">paraphrases</span> <span class="o">=</span> <span class="n">util</span><span class="p">.</span><span class="n">paraphrase_mining</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">sentences</span><span class="p">)</span>
<span class="k">for</span> <span class="n">paraphrase</span> <span class="ow">in</span> <span class="n">paraphrases</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">100</span><span class="p">]:</span>
    <span class="n">score</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="o">=</span> <span class="n">paraphrase</span>
    <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">df</span><span class="p">[</span><span class="s">'fulltext'</span><span class="p">][</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="si">{</span><span class="n">df</span><span class="p">[</span><span class="s">'fulltext'</span><span class="p">][</span><span class="n">j</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s">score:</span><span class="si">{</span><span class="n">score</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>  
</code></pre></div></div>

<p>The complete functional code in this <a href="https://colab.research.google.com/github/ccstan99/ccstan99.github.io/blob/main/docs/sbert-paraphrase-mining.ipynb">Colab notebook</a>. As you will see, the usage is straightforward for any list of sentences from your own dataset. Pick a model and try it out!</p>

<h2 id="references">References</h2>

<ul>
  <li><a href="https://arxiv.org/abs/1908.10084">Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks</a> (2019)</li>
  <li><a href="https://arxiv.org/abs/1810.04805">BERT: Bidirectional Encoder Representation for Transformers</a> (2018)</li>
  <li><a href="https://arxiv.org/abs/1907.11692">RoBERTa: Robustly Optimized BERT</a> (2019)</li>
  <li><a href="https://arxiv.org/abs/1708.00055v1">STS-b: Semantic Textual Similarity Benchmark</a> (2017)</li>
</ul>]]></content><author><name>ccstan99</name></author><summary type="html"><![CDATA[Finding Duplicates]]></summary></entry><entry><title type="html">NLP Notes</title><link href="http://localhost:4000/2022/05/09/nlp-notes.html" rel="alternate" type="text/html" title="NLP Notes" /><published>2022-05-09T00:00:00-07:00</published><updated>2022-05-09T00:00:00-07:00</updated><id>http://localhost:4000/2022/05/09/nlp-notes</id><content type="html" xml:base="http://localhost:4000/2022/05/09/nlp-notes.html"><![CDATA[<p>I just completed the <a href="https://www.coursera.org/specializations/natural-language-processing">DeepLearning.ai’s NLP specialization</a> on Coursera, went through the <a href="http://web.stanford.edu/class/cs224n/">Stanford CS224n course in NLP</a> and read a bunch of journal articles. Sorting through the alphabet soup was an undertaking in itself. Since I kept referring to my notes to compare features between the different language models and looking up benchmark datasets &amp; sources, I figured I’d pop the charts in here in case they’re helpful to others.</p>

<h2 id="language-models">Language Models</h2>

<p>Transformer specs indicate max values:
L = # layers/blocks, A = # attention heads, H = # hidden dimensions.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">year</th>
      <th style="text-align: left">model</th>
      <th style="text-align: left">description</th>
      <th>specs</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">2013</td>
      <td style="text-align: left"><a href="https://www.tensorflow.org/tutorials/text/word2vec">word2vec</a></td>
      <td style="text-align: left"><a href="https://arxiv.org/abs/1301.3781">Word Representations in Vectors</a></td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">2014</td>
      <td style="text-align: left"><a href="https://nlp.stanford.edu/projects/glove/">GloVe</a></td>
      <td style="text-align: left"><a href="https://www.semanticscholar.org/paper/GloVe%3A-Global-Vectors-for-Word-Representation-Pennington-Socher/f37e1b62a767a307c046404ca96bc140b3e68cb5">Global Vectors</a></td>
      <td> </td>
    </tr>
    <tr>
      <td style="text-align: center">2018</td>
      <td style="text-align: left"><a href="https://huggingface.co/openai-gpt">GPT</a></td>
      <td style="text-align: left"><a href="https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf">Generative Pre-trained Transformer</a></td>
      <td>L=12, A=12, H=768</td>
    </tr>
    <tr>
      <td style="text-align: center">2019</td>
      <td style="text-align: left"><a href="https://huggingface.co/gpt2">GPT-2</a></td>
      <td style="text-align: left"><a href="https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf">Unsupervised Multitask Learning</a></td>
      <td>L=48, A=48, H=1600</td>
    </tr>
    <tr>
      <td style="text-align: center">2020</td>
      <td style="text-align: left"><a href="https://beta.openai.com/docs/models/gpt-3">GPT-3</a></td>
      <td style="text-align: left"><a href="https://arxiv.org/abs/2005.14165">Few-Shot Learners</a></td>
      <td>L=96, A=96, H=12288</td>
    </tr>
    <tr>
      <td style="text-align: center">2018</td>
      <td style="text-align: left"><a href="https://huggingface.co/bert-large-cased">BERT</a></td>
      <td style="text-align: left"><a href="https://arxiv.org/abs/1810.04805">Bidirectional Encoder Representation for Transformers</a></td>
      <td>L=24, A=16, H=1024</td>
    </tr>
    <tr>
      <td style="text-align: center">2019</td>
      <td style="text-align: left"><a href="https://huggingface.co/roberta-large">RoBERTa</a></td>
      <td style="text-align: left"><a href="https://arxiv.org/abs/1907.11692">Robustly Optimized BERT</a></td>
      <td>L=24, A=16, H=1024</td>
    </tr>
    <tr>
      <td style="text-align: center">2019</td>
      <td style="text-align: left"><a href="https://huggingface.co/t5-11b">T5</a></td>
      <td style="text-align: left"><a href="https://arxiv.org/abs/1910.10683">Transfer Learning with Text-to-Text Transformer</a></td>
      <td>L=24, A=128, H=768</td>
    </tr>
  </tbody>
</table>

<h2 id="datasets">Datasets</h2>

<table>
  <thead>
    <tr>
      <th style="text-align: left">dataset</th>
      <th style="text-align: left">full name</th>
      <th style="text-align: left">description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left"><a href="https://gluebenchmark.com/"><strong>GLUE</strong></a></td>
      <td style="text-align: left"><a href="https://huggingface.co/datasets/glue">General Language Understanding Evaluation</a></td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: left">CoLA</td>
      <td style="text-align: left"><a href="https://huggingface.co/datasets/glue/viewer/cola/train">Corpus of Linguistic Acceptability</a></td>
      <td style="text-align: left">Sentence grammatically correct?</td>
    </tr>
    <tr>
      <td style="text-align: left">SST</td>
      <td style="text-align: left"><a href="https://huggingface.co/datasets/glue/viewer/sst2/train">Stanford Sentiment Treebank</a></td>
      <td style="text-align: left">Movie review sentiment analysis</td>
    </tr>
    <tr>
      <td style="text-align: left">MRPC</td>
      <td style="text-align: left"><a href="https://huggingface.co/datasets/glue/viewer/mrpc/train">Microsoft Research Paraphrase Corpus</a></td>
      <td style="text-align: left">Sentences semantically equivalent?</td>
    </tr>
    <tr>
      <td style="text-align: left">QQP</td>
      <td style="text-align: left"><a href="https://huggingface.co/datasets/glue/viewer/qqp/train">Quora Question Pairs</a></td>
      <td style="text-align: left">Sentences semantically equivalent?</td>
    </tr>
    <tr>
      <td style="text-align: left">STS-b</td>
      <td style="text-align: left"><a href="https://arxiv.org/abs/1708.00055v1">Semantic Textual Similarity Benchmark</a></td>
      <td style="text-align: left">Sentences semantically equivalent?</td>
    </tr>
    <tr>
      <td style="text-align: left">QNLI</td>
      <td style="text-align: left"><a href="https://huggingface.co/datasets/glue/viewer/qnli/train">Question-answering NLI</a></td>
      <td style="text-align: left">Sentence contains answer to question?</td>
    </tr>
    <tr>
      <td style="text-align: left">RTE</td>
      <td style="text-align: left"><a href="https://huggingface.co/datasets/glue/viewer/rte/train">Recognizing Textual Entailment</a></td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: left">WNLI</td>
      <td style="text-align: left"><a href="https://huggingface.co/datasets/glue/viewer/wnli/train">Winograd NLI</a></td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: left">MNLI</td>
      <td style="text-align: left"><a href="https://huggingface.co/datasets/SetFit/mnli">Multi-Genre NLI Corpus</a></td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: left"><a href="https://super.gluebenchmark.com/"><strong>SuperGLUE</strong></a></td>
      <td style="text-align: left"><a href="https://huggingface.co/datasets/super_glue">Stickier Benchmark for NLU</a></td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: left">BoolQ</td>
      <td style="text-align: left"><a href="https://huggingface.co/datasets/boolq">Boolean Questions</a></td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: left">CB</td>
      <td style="text-align: left">CommitmentBank</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: left">CoPA</td>
      <td style="text-align: left"><a href="https://huggingface.co/datasets/pietrolesci/copa_nli">Choice of Plausible Alternatives</a></td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: left">WSD</td>
      <td style="text-align: left"><a href="https://paperswithcode.com/task/word-sense-disambiguation">Word Sense Disambiguation</a></td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: left">WiC</td>
      <td style="text-align: left"><a href="https://paperswithcode.com/dataset/wic">Word in Context</a></td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: left">MultiRC</td>
      <td style="text-align: left"><a href="https://paperswithcode.com/dataset/multirc">Multi-Sentence Reading Comprehension</a></td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: left">ReCoRD</td>
      <td style="text-align: left"><a href="https://paperswithcode.com/dataset/record">Reading Comprehension with Commonsense Reasoning Dataset</a></td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: left">FraCaS</td>
      <td style="text-align: left"><a href="https://huggingface.co/datasets/pietrolesci/fracas">Framework for Computational Semantics</a></td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: left">SQuAD</td>
      <td style="text-align: left"><a href="https://huggingface.co/datasets/squad">Stanford Question Answering Dataset</a></td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: left">RACE</td>
      <td style="text-align: left"><a href="https://huggingface.co/datasets/race">ReAding Comprehension from Examinations</a></td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: left">LAMBADA</td>
      <td style="text-align: left"><a href="https://huggingface.co/datasets/lambada">LAnguage Modeling Broadened to Account for Discourse Aspects</a></td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: left">CBT</td>
      <td style="text-align: left"><a href="https://huggingface.co/datasets/cbt">Children’s Book Test</a></td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: left">CoQA</td>
      <td style="text-align: left"><a href="https://huggingface.co/datasets/coqa">Conversation Question Answering</a></td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: left">SWAG</td>
      <td style="text-align: left"><a href="https://huggingface.co/datasets/swag">Situations with Adversarial Generation</a></td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: left">C4</td>
      <td style="text-align: left"><a href="https://huggingface.co/datasets/c4">Colossal Clean Crawled Corpus</a></td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: left"> </td>
      <td style="text-align: left"><a href="https://huggingface.co/datasets/bookcorpus">BookCorpus</a></td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: left"> </td>
      <td style="text-align: left"><a href="https://huggingface.co/datasets/wikitext">WikiText</a></td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: left"> </td>
      <td style="text-align: left"><a href="https://huggingface.co/datasets/openwebtext">WebText</a></td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: left">PTB</td>
      <td style="text-align: left"><a href="https://paperswithcode.com/dataset/penn-treebank">Penn Treebank</a></td>
      <td style="text-align: left">Parts-of-speech tags</td>
    </tr>
    <tr>
      <td style="text-align: left">WSC</td>
      <td style="text-align: left"><a href="https://huggingface.co/datasets/winograd_wsc">Winograd Schema Challenge</a></td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: left"> </td>
      <td style="text-align: left"><a href="https://huggingface.co/datasets/winogrande">WinoGrande</a></td>
      <td style="text-align: left">Crowd-sourced WSC</td>
    </tr>
  </tbody>
</table>

<h2 id="acronyms">Acronyms</h2>

<table>
  <thead>
    <tr>
      <th style="text-align: left">term</th>
      <th style="text-align: left">expanded</th>
      <th style="text-align: left">description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">NLP</td>
      <td style="text-align: left">Natural Language Processing</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: left">NLU</td>
      <td style="text-align: left">Natural Language Understanding</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: left">NLI</td>
      <td style="text-align: left">Natural Language Inference</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: left">DPR</td>
      <td style="text-align: left">Definite Pronoun Resolution</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: left">AFS</td>
      <td style="text-align: left">Argument Facet Similarity</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: left">BiDAF</td>
      <td style="text-align: left">Bidirection Attention Flow</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: left">CoVe</td>
      <td style="text-align: left">Contextualized Word Vectors</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: left">HSIC</td>
      <td style="text-align: left">Hilbert-Schmidt Independence Criterion</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: left">PMI</td>
      <td style="text-align: left">Pointwise Mutual Information</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: left">UDA</td>
      <td style="text-align: left">Unsupervised Data Augmentation</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: left">RL2</td>
      <td style="text-align: left">Reinforcement Learning Fast &amp; Slow</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: left">MAML</td>
      <td style="text-align: left">Model-Agnostic Meta-Learning</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: left">WMT</td>
      <td style="text-align: left"><a href="https://aclanthology.org/venues/wmt/">Workshop in Machine Translation</a></td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: left">SemEval</td>
      <td style="text-align: left"><a href="https://semeval.github.io/">Workshop on Semantic Evaluatio</a></td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: left">BPE</td>
      <td style="text-align: left"><a href="https://paperswithcode.com/method/bpe">Byte-Pair Encoding</a></td>
      <td style="text-align: left">Used to tokenize &amp; build vocabulary lists</td>
    </tr>
    <tr>
      <td style="text-align: left">TF-IDF</td>
      <td style="text-align: left">Term Frequency–Inverse Document Frequency</td>
      <td style="text-align: left">Reflects word importance for document in corpus</td>
    </tr>
  </tbody>
</table>]]></content><author><name>ccstan99</name></author><summary type="html"><![CDATA[I just completed the DeepLearning.ai’s NLP specialization on Coursera, went through the Stanford CS224n course in NLP and read a bunch of journal articles. Sorting through the alphabet soup was an undertaking in itself. Since I kept referring to my notes to compare features between the different language models and looking up benchmark datasets &amp; sources, I figured I’d pop the charts in here in case they’re helpful to others.]]></summary></entry><entry><title type="html">Samples</title><link href="http://localhost:4000/2022/01/01/archive.html" rel="alternate" type="text/html" title="Samples" /><published>2022-01-01T00:00:00-08:00</published><updated>2022-01-01T00:00:00-08:00</updated><id>http://localhost:4000/2022/01/01/archive</id><content type="html" xml:base="http://localhost:4000/2022/01/01/archive.html"><![CDATA[<h2 id="interactive-projects">Interactive Projects</h2>

<ul>
  <li><strong>Nike Team Sports</strong> — Suite of uniform builders for basketball, baseball, football, camp series</li>
</ul>

<p><img src="/img/2022-01-01-archive/nike1.jpg" width="270" /> <img src="/img/2022-01-01-archive/nike3.jpg" width="270" /> <img src="/img/2022-01-01-archive/nike4.jpg" width="270" /></p>

<ul>
  <li><strong>Refractec</strong> — Eye surgery equipment tutorial for Ignite Health</li>
</ul>

<p><img src="/img/2022-01-01-archive/refractec1.jpg" width="270" /> <img src="/img/2022-01-01-archive/refractec2.jpg" width="270" /> <img src="/img/2022-01-01-archive/refractec3.jpg" width="270" /></p>

<ul>
  <li><a href="ofivina.cd">Ofivina 01</a>: CD-ROM commemorating arts exhibit &amp; festival</li>
</ul>

<p><img src="/img/2022-01-01-archive/ofivina1.jpg" width="270" /> <img src="/img/2022-01-01-archive/ofivina2.jpg" width="270" /> <img src="/img/2022-01-01-archive/ofivina4.jpg" width="270" /></p>

<p>(<a href="https://www.youtube.com/watch?v=h2rdDYZ_3bY">video demo</a>)</p>

<h2 id="websites">Websites</h2>

<p><img src="/img/2022-01-01-archive/cheng2-web.png" width="270" /> <img src="/img/2022-01-01-archive/freearts-web.png" width="270" />
<img src="/img/2022-01-01-archive/lutzky-web.png" width="270" />
<img src="/img/2022-01-01-archive/sawmeetsaw-web.png" width="270" /> <img src="/img/2022-01-01-archive/otto-web.png" width="270" /> <img src="/img/2022-01-01-archive/emily-web.png" width="270" /></p>

<h2 id="logos">Logos</h2>

<p><img src="/img/2022-01-01-archive/logos-h.svg" /></p>

<h2 id="print">Print</h2>

<p><img src="/img/2022-01-01-archive/shh-fotos-cartridge.jpg" width="200" /> <img src="/img/2022-01-01-archive/shh-fotos-mailers.jpg" width="200" /> <img src="/img/2022-01-01-archive/zing-fotos-choco.jpg" width="200" /> <img src="/img/2022-01-01-archive/zing-fotos-spice.jpg" width="200" /></p>

<h2 id="publications">Publications</h2>

<ul>
  <li>Saw, Cheng Cheng (1993) <a href="http://phonetics.linguistics.ucla.edu/facilities/physiology/epg.html">Customized 3-D Electropalatography Display</a>. UCLA Working Papers in Phonetics, 85, 71-96.</li>
  <li>D. Byrd, E. Flemming, C. A. Mueller, &amp; C. C. Tan. (1995) <a href="/docs/1995%20jshr38%20-%20Using%20Regions%20and%20Indices%20in%20EPG%20Data%20Reduction.pdf">Using regions and indices in EPG data reduction</a>. Journal of Speech and Hearing Research, 38:821-827.</li>
  <li>D. Byrd &amp; C. C. Tan. (1996) <a href="/docs/1996%20JPhon%20-%20Saying%20consonant%20clusters%20quickly.pdf">Saying consonant clusters quickly</a>. Journal of Phonetics, 24(2):263-282.</li>
  <li><a href="/docs/resume-2002.pdf">Ancient Resumé</a></li>
</ul>]]></content><author><name>ccstan99</name></author><summary type="html"><![CDATA[Interactive Projects]]></summary></entry></feed>