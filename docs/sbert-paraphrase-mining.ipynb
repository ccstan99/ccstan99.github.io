{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/ccstan99/ccstan99.github.io/blob/main/docs/sbert-paraphrase-mining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "# Sentence-BERT Paraphrase Mining\n",
        "[Sentence-BERT (SBERT)](https://sbert.net/) is a modification of BERT but is optimized for generating accurate and useful sentence embeddings. It uses Siamese and triplet network structure to derive embeddings that can be compared efficiently using cosine similarity. This reduces the time for finding the most similar pairs among 10,000 sentences from 65 hours with BERT or RoBERTa down to about 5 seconds, without sacrificing accuracy!"
      ],
      "metadata": {
        "id": "h5wdnlJIqDQG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7O-lRI0RS5Zl"
      },
      "source": [
        "## Setup\n",
        "Install the sentence-transformers module to run this notebook."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers"
      ],
      "metadata": {
        "id": "s6-z5cD5yawX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download sentences from Wiki in JSON format. Substitute and format for your own sentences."
      ],
      "metadata": {
        "id": "6flE-VEu0TeL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests, json\n",
        "import pandas as pd\n",
        "\n",
        "wikiURL = \"https://stampy.ai/w/api.php?action=ask&query=[[Canonical%20questions]]|format%3Dplainlist|%3FCanonicalQuestions&format=json\"\n",
        "wikiJSON = requests.get(wikiURL).json()\n",
        "\n",
        "df = pd.DataFrame(wikiJSON[\"query\"][\"results\"][\"Canonical questions\"][\"printouts\"][\"CanonicalQuestions\"])\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "TyrdhGQvsvFQ",
        "outputId": "7748a92b-ce71-462c-9115-27b7087a253e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            fulltext  \\\n",
              "0                              Why is AGI dangerous?   \n",
              "1              How is AGI different from current AI?   \n",
              "2               Why can't we turn the computers off?   \n",
              "3  Could we program an AI to automatically shut d...   \n",
              "4  If AI takes over the world how could it create...   \n",
              "\n",
              "                                             fullurl  namespace exists  \\\n",
              "0     https://stampy.ai/wiki/Why_is_AGI_dangerous%3F          0      1   \n",
              "1  https://stampy.ai/wiki/How_is_AGI_different_fr...          0      1   \n",
              "2  https://stampy.ai/wiki/Why_can%27t_we_turn_the...          0      1   \n",
              "3  https://stampy.ai/wiki/Could_we_program_an_AI_...          0      1   \n",
              "4  https://stampy.ai/wiki/If_AI_takes_over_the_wo...          0      1   \n",
              "\n",
              "  displaytitle  \n",
              "0               \n",
              "1               \n",
              "2               \n",
              "3               \n",
              "4               "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-350565ea-d5b1-4af5-9cde-0aaf80168028\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fulltext</th>\n",
              "      <th>fullurl</th>\n",
              "      <th>namespace</th>\n",
              "      <th>exists</th>\n",
              "      <th>displaytitle</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Why is AGI dangerous?</td>\n",
              "      <td>https://stampy.ai/wiki/Why_is_AGI_dangerous%3F</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How is AGI different from current AI?</td>\n",
              "      <td>https://stampy.ai/wiki/How_is_AGI_different_fr...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Why can't we turn the computers off?</td>\n",
              "      <td>https://stampy.ai/wiki/Why_can%27t_we_turn_the...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Could we program an AI to automatically shut d...</td>\n",
              "      <td>https://stampy.ai/wiki/Could_we_program_an_AI_...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>If AI takes over the world how could it create...</td>\n",
              "      <td>https://stampy.ai/wiki/If_AI_takes_over_the_wo...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-350565ea-d5b1-4af5-9cde-0aaf80168028')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-350565ea-d5b1-4af5-9cde-0aaf80168028 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-350565ea-d5b1-4af5-9cde-0aaf80168028');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Authorization to mount Google Drive to create output"
      ],
      "metadata": {
        "id": "rheeOy6Q0ZlU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5aW6tiD3S5Zp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03176444-e6d5-421e-fbaf-95b03ea90b57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "PATH = \"/content/drive/My Drive/Colab Notebooks\"\n",
        "\n",
        "def paraphrase_filename(model_name, current_time):\n",
        "    return PATH + \"/data/duplicate-questions.md\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paraphrase Mining to Find Duplicate Questions\n",
        "there's a evergrowing number of [pretrained sentence-transformer model checkpoints](https://sbert.net/docs/pretrained_models.html) ranked by size, speed, and other performance metrics. A model can be initialized by passing it a checkpoint that indicates a combination of both the model architecture plus the specific trained weights. Since our goal was to identify pairs of more similar questions or sentences, we tried several models that performed best on semantic search leaderboards."
      ],
      "metadata": {
        "id": "GcMl8wP1ZirN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Choose Model {display-mode: \"form\"}\n",
        "# This code will be hidden when the notebook is loaded.\n",
        "model_name = \"paraphrases-multi-qa-mpn\"  #@param ['paraphrases-multi-qa-mpn', 'distilbert-base-nli-stsb-quora-ranking', 'multi-qa-mpnet-base-dot-v1', 'all-MiniLM-L6-v2']"
      ],
      "metadata": {
        "id": "GMmHDpikbyCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `sentence_tranformers` module provides a super-handy [`paraphrase_mining`](https://sbert.net/examples/applications/paraphrase-mining/README.html#paraphrase-mining) utility that returns a list of tuples sorted by descending similarity scores along with the indices of 2 sentences from the original list of input sentences. A score of 1.0 means the 2 sentences are semantically identical, while a score of 0.0 means they are semantically unrelated."
      ],
      "metadata": {
        "id": "HkYjFNb5r11a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import time\n",
        "\n",
        "model = SentenceTransformer(model_name)\n",
        "\n",
        "# Single list of sentences - Possible tens of thousands of sentences\n",
        "sentences = df[\"fulltext\"].values.tolist()\n",
        "\n",
        "start_time = time.time()\n",
        "paraphrases = util.paraphrase_mining(model, sentences)\n",
        "end_time = time.time()\n",
        "print(f\"Elapsed time: {int((end_time - start_time)*1000)}ms\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfD5itzmWvMz",
        "outputId": "7f29b9ed-c321-45bb-f8d9-f7a7aad8b27d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 3761ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saves and prints top k=100 most similar pairs of questions. Includes some extra information for recordkeeping."
      ],
      "metadata": {
        "id": "FM5oKzHprGVN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "\n",
        "k=100\n",
        "current_time = str(datetime.datetime.now())\n",
        "with open(paraphrase_filename(model_name, current_time), 'w') as f:\n",
        "      \n",
        "    f.write(\"## Duplicate Questions\\n\")\n",
        "    f.write(f\"Language model name: {model_name}\\n\\n\")\n",
        "    f.write(f\"Date generated: {current_time}\\n\\n\")\n",
        "\n",
        "    f.write(\"| Question1 | Question2 | Score |\\n\")\n",
        "    f.write(\"| :--- | :--- | :--- |\\n\")\n",
        "\n",
        "    for paraphrase in paraphrases[0:k]:\n",
        "        score, i, j = paraphrase\n",
        "        print(f\"{df['fulltext'][i]}\\n{df['fulltext'][j]}\\nscore:{score:.2f}\\n\")\n",
        "        f.write(f\"| [{df['fulltext'][i]}]({df['fullurl'][i]}) | [{df['fulltext'][j]}]({df['fullurl'][j]}) | {score:.2f} |\\n\")   "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6v1DhNPaYAZl",
        "outputId": "e48acb2d-ba58-48fd-b0f9-0bdf6eee6ca1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Who helped create Stampy?\n",
            "Who created Stampy?\n",
            "score:0.98\n",
            "\n",
            "Is humanity doomed?\n",
            "How doomed is humanity?\n",
            "score:0.95\n",
            "\n",
            "What is a canonical question on Stampy's Wiki?\n",
            "What is a canonical version of a question on Stampy's Wiki?\n",
            "score:0.93\n",
            "\n",
            "Why can’t we just “put the AI in a box” so it can’t influence the outside world?\n",
            "Couldn’t we keep the AI in a box and never give it the ability to manipulate the external world?\n",
            "score:0.92\n",
            "\n",
            "How might a superintelligence technologically manipulate humans?\n",
            "How might a superintelligence socially manipulate humans?\n",
            "score:0.92\n",
            "\n",
            "Why is AI Safety important?\n",
            "Why is safety important for smarter-than-human AI?\n",
            "score:0.91\n",
            "\n",
            "Can we tell an AI just to figure out what we want, then do that?\n",
            "Can we just tell an AI to do what we want?\n",
            "score:0.90\n",
            "\n",
            "What is AI Safety?\n",
            "Why is AI Safety important?\n",
            "score:0.90\n",
            "\n",
            "I’d like a good introduction to AI alignment. Where can I find one?\n",
            "What are good resources on AI alignment?\n",
            "score:0.89\n",
            "\n",
            "I’d like to get deeper into the AI alignment literature. Where should I look?\n",
            "What are good resources on AI alignment?\n",
            "score:0.89\n",
            "\n",
            "I’d like to get deeper into the AI alignment literature. Where should I look?\n",
            "I’d like a good introduction to AI alignment. Where can I find one?\n",
            "score:0.89\n",
            "\n",
            "Who is Stampy?\n",
            "Who created Stampy?\n",
            "score:0.88\n",
            "\n",
            "Will there be an AI assisted long reflection and how might it look like?\n",
            "How might an AI enabled long reflection look?\n",
            "score:0.88\n",
            "\n",
            "What is a canonical question on Stampy's Wiki?\n",
            "What should be marked as a canonical answer on Stampy's Wiki?\n",
            "score:0.88\n",
            "\n",
            "How does AI taking things literally contribute to alignment being hard?\n",
            "Why is AI alignment hard?\n",
            "score:0.87\n",
            "\n",
            "What is Evidential Decision Theory?\n",
            "What is Logical Decision Theory?\n",
            "score:0.87\n",
            "\n",
            "When will an intelligence explosion happen?\n",
            "Might an intelligence explosion never occur?\n",
            "score:0.86\n",
            "\n",
            "How likely is an intelligence explosion?\n",
            "When will an intelligence explosion happen?\n",
            "score:0.86\n",
            "\n",
            "How likely is an intelligence explosion?\n",
            "Might an intelligence explosion never occur?\n",
            "score:0.86\n",
            "\n",
            "Who is Stampy?\n",
            "Who helped create Stampy?\n",
            "score:0.86\n",
            "\n",
            "Why does there seem to have been an explosion of activity in AI in recent years?\n",
            "Why is the future of AI suddenly in the news? What has changed?\n",
            "score:0.86\n",
            "\n",
            "How could an intelligence explosion be useful?\n",
            "How might an intelligence explosion be dangerous?\n",
            "score:0.86\n",
            "\n",
            "Where can I find questions to answer for Stampy?\n",
            "What kind of questions do we want on Stampy?\n",
            "score:0.86\n",
            "\n",
            "What's especially worrisome about autonomous weapons?\n",
            "Isn't the real concern autonomous weapons?\n",
            "score:0.86\n",
            "\n",
            "How likely is an intelligence explosion?\n",
            "How might an intelligence explosion be dangerous?\n",
            "score:0.85\n",
            "\n",
            "What is a canonical question on Stampy's Wiki?\n",
            "What is a duplicate question on Stampy's Wiki?\n",
            "score:0.85\n",
            "\n",
            "What is AI alignment?\n",
            "What is the general nature of the concern about AI alignment?\n",
            "score:0.85\n",
            "\n",
            "Can an AI really be smarter than humans?\n",
            "Why think that AI can outperform humans?\n",
            "score:0.85\n",
            "\n",
            "I want to work on AI alignment. How can I get funding?\n",
            "How can I get hired by an organization working on AI alignment?\n",
            "score:0.85\n",
            "\n",
            "What is the intelligence explosion?\n",
            "How could an intelligence explosion be useful?\n",
            "score:0.84\n",
            "\n",
            "Why is AI alignment hard?\n",
            "What kind of a challenge is solving AI alignment?\n",
            "score:0.84\n",
            "\n",
            "What is AI alignment?\n",
            "Is AI alignment possible?\n",
            "score:0.84\n",
            "\n",
            "Wouldn't a superintelligence be smart enough not to make silly mistakes in its comprehension of our instructions?\n",
            "Wouldn't a superintelligence be smart enough to know right from wrong?\n",
            "score:0.84\n",
            "\n",
            "What is a canonical version of a question on Stampy's Wiki?\n",
            "What is a duplicate question on Stampy's Wiki?\n",
            "score:0.84\n",
            "\n",
            "What is the general nature of the concern about AI alignment?\n",
            "What are some of the most carefully thought out objections to AI alignment?\n",
            "score:0.84\n",
            "\n",
            "What would an actually good solution to AI alignment look like?\n",
            "What’s a good AI alignment elevator pitch?\n",
            "score:0.84\n",
            "\n",
            "What is Causal Decision Theory?\n",
            "What is Logical Decision Theory?\n",
            "score:0.83\n",
            "\n",
            "How can I collect questions for Stampy?\n",
            "Where can I find questions to answer for Stampy?\n",
            "score:0.83\n",
            "\n",
            "Is AI alignment possible?\n",
            "Can we ever be sure an AI is aligned?\n",
            "score:0.83\n",
            "\n",
            "Are there AI alignment projects which governments could usefully put a very large amount of resources into?\n",
            "Is there something useful we can ask governments to do for AI alignment?\n",
            "score:0.83\n",
            "\n",
            "What are common objections to AI alignment and brief responses?\n",
            "What are some of the most carefully thought out objections to AI alignment?\n",
            "score:0.83\n",
            "\n",
            "What is the intelligence explosion?\n",
            "When will an intelligence explosion happen?\n",
            "score:0.83\n",
            "\n",
            "Is AI alignment possible?\n",
            "What would an actually good solution to AI alignment look like?\n",
            "score:0.83\n",
            "\n",
            "I'm interested in working on AI Safety. What should I do?\n",
            "How do I know whether I'm a good fit for work on AI safety?\n",
            "score:0.83\n",
            "\n",
            "Would AI alignment be hard with deep learning?\n",
            "Why is AI alignment hard?\n",
            "score:0.83\n",
            "\n",
            "What are the different possible AI takeoff speeds?\n",
            "How fast will AI takeoff be?\n",
            "score:0.82\n",
            "\n",
            "How can I contribute to Stampy?\n",
            "Why might contributing to Stampy be worth my time?\n",
            "score:0.82\n",
            "\n",
            "What approaches are AI alignment organizations working on?\n",
            "What would an actually good solution to AI alignment look like?\n",
            "score:0.82\n",
            "\n",
            "Why is AGI dangerous?\n",
            "Why don't we just not build AGI if it's so dangerous?\n",
            "score:0.82\n",
            "\n",
            "What is a canonical version of a question on Stampy's Wiki?\n",
            "What should be marked as a canonical answer on Stampy's Wiki?\n",
            "score:0.82\n",
            "\n",
            "What is AI alignment?\n",
            "Why is AI alignment hard?\n",
            "score:0.82\n",
            "\n",
            "What is Logical Decision Theory?\n",
            "What is Functional Decision Theory?\n",
            "score:0.82\n",
            "\n",
            "What is AI Safety?\n",
            "Why is safety important for smarter-than-human AI?\n",
            "score:0.82\n",
            "\n",
            "What is Evidential Decision Theory?\n",
            "What is Causal Decision Theory?\n",
            "score:0.82\n",
            "\n",
            "What is a follow-up question on Stampy's Wiki?\n",
            "What is a duplicate question on Stampy's Wiki?\n",
            "score:0.81\n",
            "\n",
            "What about AI concerns other than existential safety?\n",
            "What are some problems in philosophy that are related to AI safety?\n",
            "score:0.81\n",
            "\n",
            "Might an intelligence explosion never occur?\n",
            "How might an intelligence explosion be dangerous?\n",
            "score:0.81\n",
            "\n",
            "What are the potential benefits of AI as it grows increasingly sophisticated?\n",
            "What technological developments could speed up AI progress?\n",
            "score:0.81\n",
            "\n",
            "What is the intelligence explosion?\n",
            "How might an intelligence explosion be dangerous?\n",
            "score:0.81\n",
            "\n",
            "What is AI alignment?\n",
            "What are some important terms in AI alignment?\n",
            "score:0.81\n",
            "\n",
            "What should be marked as a related question on Stampy's Wiki?\n",
            "What is a follow-up question on Stampy's Wiki?\n",
            "score:0.81\n",
            "\n",
            "Is AI alignment possible?\n",
            "Why is AI alignment hard?\n",
            "score:0.81\n",
            "\n",
            "What would an actually good solution to AI alignment look like?\n",
            "Are there promising ways to make AI alignment researchers smarter?\n",
            "score:0.81\n",
            "\n",
            "What is AI alignment?\n",
            "What kind of a challenge is solving AI alignment?\n",
            "score:0.81\n",
            "\n",
            "What is the general nature of the concern about AI alignment?\n",
            "What kind of a challenge is solving AI alignment?\n",
            "score:0.81\n",
            "\n",
            "In what ways could weak AI systems help with alignment research?\n",
            "Are there promising ways to make AI alignment researchers smarter?\n",
            "score:0.81\n",
            "\n",
            "What is AI alignment?\n",
            "What would an actually good solution to AI alignment look like?\n",
            "score:0.81\n",
            "\n",
            "What is a follow-up question on Stampy's Wiki?\n",
            "What is a canonical version of a question on Stampy's Wiki?\n",
            "score:0.81\n",
            "\n",
            "What would an actually good solution to AI alignment look like?\n",
            "What kind of a challenge is solving AI alignment?\n",
            "score:0.81\n",
            "\n",
            "Do you need a PhD to work on AI Safety?\n",
            "I'm interested in working on AI Safety. What should I do?\n",
            "score:0.81\n",
            "\n",
            "What approaches are AI alignment organizations working on?\n",
            "Are there promising ways to make AI alignment researchers smarter?\n",
            "score:0.81\n",
            "\n",
            "Why is AGI dangerous?\n",
            "How might AGI kill people?\n",
            "score:0.80\n",
            "\n",
            "How can I support alignment researchers to be more productive?\n",
            "Could I contribute by offering coaching to alignment researchers? If so, how would I go about this?\n",
            "score:0.80\n",
            "\n",
            "What would an actually good solution to AI alignment look like?\n",
            "What are good resources on AI alignment?\n",
            "score:0.80\n",
            "\n",
            "What is AI alignment?\n",
            "What are good resources on AI alignment?\n",
            "score:0.80\n",
            "\n",
            "Why is AI Safety important?\n",
            "Why work on AI safety early?\n",
            "score:0.80\n",
            "\n",
            "What can we do to contribute to AI safety?\n",
            "Why is AI Safety important?\n",
            "score:0.80\n",
            "\n",
            "What would an actually good solution to AI alignment look like?\n",
            "What is the general nature of the concern about AI alignment?\n",
            "score:0.80\n",
            "\n",
            "Isn’t it immoral to control and impose our values on AI?\n",
            "Could we tell the AI to do what's morally right?\n",
            "score:0.80\n",
            "\n",
            "What is the intelligence explosion?\n",
            "How likely is an intelligence explosion?\n",
            "score:0.80\n",
            "\n",
            "Why should I worry about superintelligence?\n",
            "Why might a superintelligence be dangerous?\n",
            "score:0.80\n",
            "\n",
            "Can’t we just program the superintelligence not to harm us?\n",
            "Once we notice that a superintelligence given a specific task is starting to try to take over the world, can’t we turn it off, reprogram it, or otherwise correct the problem?\n",
            "score:0.80\n",
            "\n",
            "What about AI concerns other than existential safety?\n",
            "What organizations are working on AI existential safety?\n",
            "score:0.80\n",
            "\n",
            "I'm interested in working on AI Safety. What should I do?\n",
            "How do I form my own views about AI safety?\n",
            "score:0.80\n",
            "\n",
            "What is the general nature of the concern about AI alignment?\n",
            "Why is AI alignment hard?\n",
            "score:0.80\n",
            "\n",
            "What will be the first transformative applications of AI?\n",
            "What military applications of AI will likely exist?\n",
            "score:0.80\n",
            "\n",
            "I’d like a good introduction to AI alignment. Where can I find one?\n",
            "What’s a good AI alignment elevator pitch?\n",
            "score:0.80\n",
            "\n",
            "When will transformative AI be created?\n",
            "What will be the first transformative applications of AI?\n",
            "score:0.80\n",
            "\n",
            "What approaches are AI alignment organizations working on?\n",
            "Are there AI alignment projects which governments could usefully put a very large amount of resources into?\n",
            "score:0.80\n",
            "\n",
            "Might an intelligence explosion never occur?\n",
            "How could an intelligence explosion be useful?\n",
            "score:0.79\n",
            "\n",
            "What’s a good AI alignment elevator pitch?\n",
            "What are good resources on AI alignment?\n",
            "score:0.79\n",
            "\n",
            "What approaches are AI alignment organizations working on?\n",
            "What are good resources on AI alignment?\n",
            "score:0.79\n",
            "\n",
            "If AGI comes from a new paradigm, how likely is it to arise late in the paradigm when it is already deployed at scale versus early when a few people are exploring the idea?\n",
            "How likely is it that AGI is first developed by a large established org, versus a small startup-y org, versus an academic group, versus a government?\n",
            "score:0.79\n",
            "\n",
            "What are the potential benefits of AI as it grows increasingly sophisticated?\n",
            "What will be the first transformative applications of AI?\n",
            "score:0.79\n",
            "\n",
            "Why is AI Safety important?\n",
            "What are some problems in philosophy that are related to AI safety?\n",
            "score:0.79\n",
            "\n",
            "Would AI alignment be hard with deep learning?\n",
            "Is AI alignment possible?\n",
            "score:0.79\n",
            "\n",
            "Why might people try to build AGI rather than stronger and stronger narrow AIs?\n",
            "Wouldn't it be safer to only build narrow AIs?\n",
            "score:0.79\n",
            "\n",
            "Isn’t AI just a tool like any other? Won’t AI just do what we tell it to do?\n",
            "Can we just tell an AI to do what we want?\n",
            "score:0.79\n",
            "\n",
            "What approaches are AI alignment organizations working on?\n",
            "What kind of a challenge is solving AI alignment?\n",
            "score:0.79\n",
            "\n",
            "What are some important terms in AI alignment?\n",
            "What are good resources on AI alignment?\n",
            "score:0.79\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"File generated at:\\n{paraphrase_filename(model_name, current_time)}\") "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1b9_hPHI1B_U",
        "outputId": "593e598f-1b46-4c4b-bae1-5d1995c0789e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File generated at:\n",
            "/content/drive/My Drive/Colab Notebooks/data/stampy-duplicate-questions.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Additional SBERT Resources\n",
        "- [Paraphrase Mining](https://sbert.net/examples/applications/paraphrase-mining/README.html#paraphrase-mining)\n",
        "- [Semantic Search](https://sbert.net/examples/applications/semantic-search/README.html#util-semantic-search)\n",
        "- [Storing & Loading Embeddings](https://sbert.net/examples/applications/computing-embeddings/README.html#storing-loading-embeddings)\n",
        "- [Topic Modeling](https://sbert.net/examples/applications/clustering/README.html#topic-modeling)"
      ],
      "metadata": {
        "id": "lyZLKdohZvII"
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "Sentence-BERT Paraphrase Mining (PyTorch)",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}