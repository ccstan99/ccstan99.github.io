---
layout: post
title: "NLP Notes"
subtitle: "Models and Dataset References"
background: '/img/posts/2022-05-09-nlp-notes.jpg'
---
I just finished the [DeepLearning.ai's NLP specialization](https://www.coursera.org/specializations/natural-language-processing) on Coursera, went through the [Stanford CS224n course in NLP](http://web.stanford.edu/class/cs224n/) and read a bunch of journal articles. Sorting through the alphabet soup was an undertaking in itself. Since I kept referring to my notes to compare features between the different language models and looking up benchmark datasets & sources, I figured I'd pop the tables in here in case they're helpful for others.

## Language Models

| year  | model | description | specs |
| :---: | :---- | :---------- | ----- | 
| 2013 | [word2vec](https://www.tensorflow.org/tutorials/text/word2vec) | [Word Representations in Vectors](https://arxiv.org/abs/1301.3781) |
| 2014 | [GloVe](https://nlp.stanford.edu/projects/glove/) | [Global Vectors](https://www.semanticscholar.org/paper/GloVe%3A-Global-Vectors-for-Word-Representation-Pennington-Socher/f37e1b62a767a307c046404ca96bc140b3e68cb5)
| 2018 | [GPT](https://huggingface.co/openai-gpt) | [Generative Pre-trained Transformer](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf) |
| 2018 | [BERT](https://huggingface.co/bert-large-cased) | [Bidirectional Encoder Representation for Transformers](https://arxiv.org/abs/1810.04805) |
| 2019 | [GPT-2](https://huggingface.co/gpt2) | [Unsupervised Multitask Learning](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf) |
| 2019 | [RoBERTa](https://huggingface.co/roberta-large) | [Robustly Optimized BERT](https://arxiv.org/abs/1907.11692) |
| 2019 | [T5](https://huggingface.co/t5-11b) | [Transfer Learning with Text-to-Text Transformer](https://arxiv.org/abs/1910.10683) |
| 2020 | [GPT-3](https://beta.openai.com/docs/models/gpt-3) | [Few-Shot Learners](https://arxiv.org/abs/2005.14165) |

## Datasets

| dataset | full name | description |
| :------ | :-------- | :---------- |
| | [**GLUE**<br>General Language Understanding Evaluation](https://huggingface.co/datasets/glue)
| CoLA | [Corpus of Linguistic Acceptability](https://huggingface.co/datasets/glue/viewer/cola/train) | Grammatically correct sentence?
| SST | [Stanford Sentiment Treebank](https://huggingface.co/datasets/glue/viewer/sst2/train) | Sentiment analysis of movie reviews
| MRPC | [Microsoft Research Paraphrase Corpus](https://huggingface.co/datasets/glue/viewer/mrpc/train) | Sentence pairs semantically equivalent?
| QQP | [Quora Question Pairs](https://huggingface.co/datasets/glue/viewer/qqp/train) | Sentence pairs semantically equivalent?
| STS-b | [Semantic Textual Similarity benchmark](https://arxiv.org/abs/1708.00055v1) | Sentence pairs semantically equivalent?
| QNLI | [Question-answering NLI](https://huggingface.co/datasets/glue/viewer/qnli/train) | Context sentence contains answer to question?
| RTE | [Recognizing Textual Entailment](https://huggingface.co/datasets/glue/viewer/rte/train) | Wikipedia/news sentence entails a given hypothesis?
| WNLI | [Winograd NLI](https://huggingface.co/datasets/glue/viewer/wnli/train) | Reading comprehension, pronoun coreference resolution
| MNLI | [Multi-Genre NLI Corpus](https://huggingface.co/datasets/SetFit/mnli) | Premise & hypothesis textual (entailment contradiction, neutral), matched (in-domain)/mismatched 
| | [**SuperGLUE**](https://huggingface.co/datasets/super_glue)
| BoolQ | [Boolean Questions](https://huggingface.co/datasets/boolq)
| CB | CommitmentBank
| CoPA | [Choice of Plausible Alternatives](https://huggingface.co/datasets/pietrolesci/copa_nli)
| DPR | Definite Pronoun Resolution
| SemEval | Semantic Evaluation
| FraCaS | [Framework for Computational Semantics](https://huggingface.co/datasets/pietrolesci/fracas)
| SQuAD | [Stanford Question Answering Dataset](https://huggingface.co/datasets/squad) | Question answering
| RACE | [ReAding Comprehension from Examinations](https://huggingface.co/datasets/race) | Question answering
| LAMBADA | [LAnguage Modeling Broadened to Account for Discourse Aspects](https://huggingface.co/datasets/lambada) | Long range dependencies
| CBT | [Children's Book Test](https://huggingface.co/datasets/cbt)
| CoQA | [Conversation Question Answering](https://huggingface.co/datasets/coqa)
| SWAG | [Situations with Adversarial Generation](https://huggingface.co/datasets/swag)
| C4 | [Colossal Clean Crawled Corpus](https://huggingface.co/datasets/c4)
| WSC | [Winograd Schema Challenge](https://huggingface.co/datasets/winograd_wsc)
| | [Winogrande](https://huggingface.co/datasets/winogrande)
| WSD | Word Sense Disambiguation
| MultiRC | Multi-Sentence Reading Comprehension
| ReCoRD | Reading Comprehension with Commonsense Reasoning Dataset
| WiC | Word in Context
| AFS | Argument Facet Similarity

## Acronyms

| term | description |
| :--- | :---------- | 
| NLP | Natural Language Processing
| NLU | Natural Language Understanding
| NLI | Natural Language Inference
| BiDAF | Bidirection Attention Flow
| BPE | Byte-Pair Encoding
| WMT | Workshop in Machine Translation
| CoVe | Contextualized Word Vectors
| HSIC | Hilbert-Schmidt Independence Criterion
| PMI | Pointwise Mutual Information
| UDA | Unsupervised Data Augmentation
| RL2 | Reinforcement Learning Fast & Slow
| MAML | Model-Agnostic Meta-Learning
| TF-IDF | Term Frequencyâ€“Inverse Document Frequency | Reflects how important a word is to a document in a collection or corpus
