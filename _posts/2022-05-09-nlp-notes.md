---
layout: post
title: "NLP Notes"
subtitle: "Models and Dataset References"
background: '/img/posts/2022-05-09-nlp-notes.jpg'
---
I just completed the [DeepLearning.ai's NLP specialization](https://www.coursera.org/specializations/natural-language-processing) on Coursera, went through the [Stanford CS224n course in NLP](http://web.stanford.edu/class/cs224n/) and read a bunch of journal articles. Sorting through the alphabet soup was an undertaking in itself. Since I kept referring to my notes to compare features between the different language models and looking up benchmark datasets & sources, I figured I'd pop the charts in here in case they're helpful to others.

## Language Models

Transformer specs indicate max values:
L = # layers/blocks, A = # attention heads, H = # hidden dimensions.

| year  | model | description | specs |
| :---: | :---- | :---------- | ----- |
| 2013 | [word2vec](https://www.tensorflow.org/tutorials/text/word2vec) | [Word Representations in Vectors](https://arxiv.org/abs/1301.3781) |
| 2014 | [GloVe](https://nlp.stanford.edu/projects/glove/) | [Global Vectors](https://www.semanticscholar.org/paper/GloVe%3A-Global-Vectors-for-Word-Representation-Pennington-Socher/f37e1b62a767a307c046404ca96bc140b3e68cb5)
| 2018 | [GPT](https://huggingface.co/openai-gpt) | [Generative Pre-trained Transformer](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf) | L=12, A=12, H=768
| 2019 | [GPT-2](https://huggingface.co/gpt2) | [Unsupervised Multitask Learning](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf) |  L=48, A=??, H=1600
| 2020 | [GPT-3](https://beta.openai.com/docs/models/gpt-3) | [Few-Shot Learners](https://arxiv.org/abs/2005.14165) | L=96, A=??, H=12288
| 2018 | [BERT](https://huggingface.co/bert-large-cased) | [Bidirectional Encoder Representation for Transformers](https://arxiv.org/abs/1810.04805) | L=24, A=16, H=1024
| 2019 | [RoBERTa](https://huggingface.co/roberta-large) | [Robustly Optimized BERT](https://arxiv.org/abs/1907.11692) | L=24, A=16, H=1024
| 2019 | [T5](https://huggingface.co/t5-11b) | [Transfer Learning with Text-to-Text Transformer](https://arxiv.org/abs/1910.10683) | L=24, A=128, H=768

## Datasets

| dataset | full name | description |
| :------ | :-------- | :---------- |
| [**GLUE**](https://gluebenchmark.com/) | [General Language Understanding Evaluation](https://huggingface.co/datasets/glue)
| CoLA | [Corpus of Linguistic Acceptability](https://huggingface.co/datasets/glue/viewer/cola/train) | Sentence grammatically correct?
| SST | [Stanford Sentiment Treebank](https://huggingface.co/datasets/glue/viewer/sst2/train) | Movie review sentiment analysis
| MRPC | [Microsoft Research Paraphrase Corpus](https://huggingface.co/datasets/glue/viewer/mrpc/train) | Sentences semantically equivalent?
| QQP | [Quora Question Pairs](https://huggingface.co/datasets/glue/viewer/qqp/train) | Sentences semantically equivalent?
| STS-b | [Semantic Textual Similarity Benchmark](https://arxiv.org/abs/1708.00055v1) | Sentences semantically equivalent?
| QNLI | [Question-answering NLI](https://huggingface.co/datasets/glue/viewer/qnli/train) | Sentence contains answer to question?
| RTE | [Recognizing Textual Entailment](https://huggingface.co/datasets/glue/viewer/rte/train) |
| WNLI | [Winograd NLI](https://huggingface.co/datasets/glue/viewer/wnli/train) |
| MNLI | [Multi-Genre NLI Corpus](https://huggingface.co/datasets/SetFit/mnli) |
| [**SuperGLUE**](https://super.gluebenchmark.com/) |  [Stickier Benchmark for NLU](https://huggingface.co/datasets/super_glue)
| BoolQ | [Boolean Questions](https://huggingface.co/datasets/boolq)
| CB | CommitmentBank
| CoPA | [Choice of Plausible Alternatives](https://huggingface.co/datasets/pietrolesci/copa_nli)
| WSD | [Word Sense Disambiguation](https://paperswithcode.com/task/word-sense-disambiguation)
| WiC | [Word in Context](https://paperswithcode.com/dataset/wic)
| MultiRC | [Multi-Sentence Reading Comprehension](https://paperswithcode.com/dataset/multirc)
| ReCoRD | [Reading Comprehension with Commonsense Reasoning Dataset](https://paperswithcode.com/dataset/record)
| FraCaS | [Framework for Computational Semantics](https://huggingface.co/datasets/pietrolesci/fracas)
| SQuAD | [Stanford Question Answering Dataset](https://huggingface.co/datasets/squad) |
| RACE | [ReAding Comprehension from Examinations](https://huggingface.co/datasets/race) |
| LAMBADA | [LAnguage Modeling Broadened to Account for Discourse Aspects](https://huggingface.co/datasets/lambada) |
| CBT | [Children's Book Test](https://huggingface.co/datasets/cbt)
| CoQA | [Conversation Question Answering](https://huggingface.co/datasets/coqa)
| SWAG | [Situations with Adversarial Generation](https://huggingface.co/datasets/swag)
| C4 | [Colossal Clean Crawled Corpus](https://huggingface.co/datasets/c4)
| WSC | [Winograd Schema Challenge](https://huggingface.co/datasets/winograd_wsc)
| | [WinoGrande](https://huggingface.co/datasets/winogrande) | Crowd-sourced WSC

## Acronyms

| term | expanded | description |
| :--- | :------- | :---------- |
| NLP | Natural Language Processing
| NLU | Natural Language Understanding
| NLI | Natural Language Inference
| DPR | Definite Pronoun Resolution
| AFS | Argument Facet Similarity
| BiDAF | Bidirection Attention Flow
| CoVe | Contextualized Word Vectors
| HSIC | Hilbert-Schmidt Independence Criterion
| PMI | Pointwise Mutual Information
| UDA | Unsupervised Data Augmentation
| RL2 | Reinforcement Learning Fast & Slow
| MAML | Model-Agnostic Meta-Learning
| BPE | [Byte-Pair Encoding](https://paperswithcode.com/method/bpe)
| WMT | [Workshop in Machine Translation](https://aclanthology.org/venues/wmt/)
| SemEval | [Workshop on Semantic Evaluatio](https://semeval.github.io/) |
| TF-IDF | Term Frequencyâ€“Inverse Document Frequency | Reflects word importance for document in corpus
