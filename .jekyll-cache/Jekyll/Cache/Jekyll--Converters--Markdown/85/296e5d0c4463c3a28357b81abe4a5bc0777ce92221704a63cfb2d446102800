I"º&<p>I just finished the <a href="https://www.coursera.org/specializations/natural-language-processing">DeepLearning.aiâ€™s NLP specialization</a> on Coursera. I also went through the <a href="http://web.stanford.edu/class/cs224n/">Stanford CS224n course in NLP</a> and read a bunch of journal articles. Sorting through alphabet soup was an undertaking in itself. Since I kept referring to my notes to compare features between the different language models and looking up benchmark datasets &amp; sources, I figured Iâ€™d plop the charts here in case theyâ€™re helpful for others.</p>

<h2 id="language-models">Language Models</h2>

<table>
  <thead>
    <tr>
      <th style="text-align: center">year</th>
      <th style="text-align: left">model</th>
      <th style="text-align: left">description</th>
      <th>specs</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">2013</td>
      <td style="text-align: left">word2vec</td>
      <td style="text-align: left"><a href="https://arxiv.org/abs/1301.3781">Word Representations in Vectors</a></td>
      <td>Â </td>
    </tr>
    <tr>
      <td style="text-align: center">2014</td>
      <td style="text-align: left">GloVe</td>
      <td style="text-align: left"><a href="https://www.semanticscholar.org/paper/GloVe%3A-Global-Vectors-for-Word-Representation-Pennington-Socher/f37e1b62a767a307c046404ca96bc140b3e68cb5">Global Vectors</a></td>
      <td>Â </td>
    </tr>
    <tr>
      <td style="text-align: center">2018</td>
      <td style="text-align: left">GPT</td>
      <td style="text-align: left"><a href="https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf">Generative Pre-trained Transformer</a></td>
      <td>Â </td>
    </tr>
    <tr>
      <td style="text-align: center">2018</td>
      <td style="text-align: left">BERT</td>
      <td style="text-align: left"><a href="https://arxiv.org/abs/1810.04805">Bidirectional Encoder Representation for Transformers</a></td>
      <td>Â </td>
    </tr>
    <tr>
      <td style="text-align: center">2019</td>
      <td style="text-align: left">GPT-2</td>
      <td style="text-align: left"><a href="https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf">Unsupervised Multitask Learning</a></td>
      <td>Â </td>
    </tr>
    <tr>
      <td style="text-align: center">2019</td>
      <td style="text-align: left">RoBERTa</td>
      <td style="text-align: left"><a href="https://arxiv.org/abs/1907.11692">Robustly Optimized BERT</a></td>
      <td>Â </td>
    </tr>
    <tr>
      <td style="text-align: center">2019</td>
      <td style="text-align: left">T5</td>
      <td style="text-align: left"><a href="https://arxiv.org/abs/1910.10683">Transfer Learning with Text-to-Text Transformer</a></td>
      <td>Â </td>
    </tr>
    <tr>
      <td style="text-align: center">2020</td>
      <td style="text-align: left">GPT-3</td>
      <td style="text-align: left"><a href="https://arxiv.org/abs/2005.14165">Few-Shot Learners</a></td>
      <td>Â </td>
    </tr>
  </tbody>
</table>

<h2 id="datasets">Datasets</h2>

<p>| dataset | full name | description |
| :â€”â€” | :â€”â€”â€“ | :â€”â€”â€”- |
| GLUE | <a href="https://huggingface.co/datasets/glue">General Language Understanding Evaluation Benchmark</a>
| CoLA | <a href="https://huggingface.co/datasets/glue/viewer/cola/train">Corpus of Linguistic Acceptability</a> | Grammatically correct sentence?
| SST | <a href="https://huggingface.co/datasets/glue/viewer/sst2/train">Stanford Sentiment Treebank</a> | Sentiment analysis of movie reviews
| MRPC | <a href="https://huggingface.co/datasets/glue/viewer/mrpc/train">Microsoft Research Paraphrase Corpus</a> | Sentence pairs semantically equivalent?
| QQP | <a href="https://huggingface.co/datasets/glue/viewer/qqp/train">Quora Question Pairs</a> | Sentence pairs semantically equivalent?
| STS-b | <a href="https://arxiv.org/abs/1708.00055v1">Semantic Textual Similarity benchmark</a> | Sentence pairs semantically equivalent?
| QNLI | <a href="https://huggingface.co/datasets/glue/viewer/qnli/train">Question-answering NLI</a> | Context sentence contains answer to question?
(cross-domain)</p>

<table>
  <tbody>
    <tr>
      <td>RTE</td>
      <td><a href="https://huggingface.co/datasets/glue/viewer/rte/train">Recognizing Textual Entailment</a></td>
      <td>Wikipedia/news sentence entails a given hypothesis?</td>
    </tr>
  </tbody>
</table>

<table>
  <tbody>
    <tr>
      <td>WNLI</td>
      <td><a href="https://huggingface.co/datasets/glue/viewer/wnli/train">Winograd NLI</a></td>
      <td>Reading comprehension, pronoun coreference resolution</td>
    </tr>
    <tr>
      <td>MNLI</td>
      <td><a href="https://huggingface.co/datasets/SetFit/mnli">Multi-Genre NLI Corpus</a></td>
      <td>Premise &amp; hypothesis textual (entailment contradiction, neutral), matched (in-domain)/mismatched</td>
    </tr>
    <tr>
      <td>SuperGLUE</td>
      <td><a href="https://huggingface.co/datasets/super_glue">SuperGLUE</a></td>
      <td>Â </td>
    </tr>
    <tr>
      <td>BoolQ</td>
      <td><a href="https://huggingface.co/datasets/boolq">Boolean Questions</a></td>
      <td>Â </td>
    </tr>
    <tr>
      <td>CB</td>
      <td>CommitmentBank</td>
      <td>Â </td>
    </tr>
    <tr>
      <td>CoPA</td>
      <td>Choice of Plausible Alternatives</td>
      <td>Â </td>
    </tr>
    <tr>
      <td>DPR</td>
      <td>Definite Pronoun Resolution</td>
      <td>Â </td>
    </tr>
    <tr>
      <td>SemEval</td>
      <td>Semantic Evaluation</td>
      <td>Â </td>
    </tr>
    <tr>
      <td>FraCaS</td>
      <td>Framework for Computational Semantics</td>
      <td>Â </td>
    </tr>
    <tr>
      <td>SQuAD</td>
      <td><a href="https://huggingface.co/datasets/squad">Stanford Question Answering Dataset</a></td>
      <td>Question answering</td>
    </tr>
    <tr>
      <td>RACE</td>
      <td><a href="https://huggingface.co/datasets/race">ReAding Comprehension from Examinations</a></td>
      <td>Question answering</td>
    </tr>
    <tr>
      <td>LAMBADA</td>
      <td><a href="https://huggingface.co/datasets/lambada">LAnguage Modeling Broadened to Account for Discourse Aspects</a></td>
      <td>Long range dependencies</td>
    </tr>
    <tr>
      <td>CBT</td>
      <td><a href="https://huggingface.co/datasets/cbt">Childrenâ€™s Book Test</a></td>
      <td>Â </td>
    </tr>
    <tr>
      <td>CoQA</td>
      <td><a href="https://huggingface.co/datasets/coqa">Conversation Question Answering</a></td>
      <td>Â </td>
    </tr>
    <tr>
      <td>SWAG</td>
      <td><a href="https://huggingface.co/datasets/swag">Situations with Adversarial Generation</a></td>
      <td>Â </td>
    </tr>
    <tr>
      <td>C4</td>
      <td><a href="https://huggingface.co/datasets/c4">Colossal Clean Crawled Corpus</a></td>
      <td>Â </td>
    </tr>
    <tr>
      <td>WSD</td>
      <td>Word Sense Disambiguation</td>
      <td>Â </td>
    </tr>
    <tr>
      <td>MultiRC</td>
      <td>Multi-Sentence Reading Comprehension</td>
      <td>Â </td>
    </tr>
    <tr>
      <td>ReCoRD</td>
      <td>Reading Comprehension with Commonsense Reasoning Dataset</td>
      <td>Â </td>
    </tr>
    <tr>
      <td>WiC</td>
      <td>Word in Context</td>
      <td>Â </td>
    </tr>
    <tr>
      <td>WSC</td>
      <td><a href="http://commonsensereasoning.org/2011/papers/Levesque.pdf">Winograd Schema Challenge</a></td>
      <td>Â </td>
    </tr>
    <tr>
      <td>AFS</td>
      <td>Argument Facet Similarity</td>
      <td>Â </td>
    </tr>
  </tbody>
</table>

<h2 id="acronyms">Acronyms</h2>

<table>
  <thead>
    <tr>
      <th style="text-align: left">term</th>
      <th style="text-align: left">description</th>
      <th>Â </th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">NLP</td>
      <td style="text-align: left">Natural Language Processing</td>
      <td>Â </td>
    </tr>
    <tr>
      <td style="text-align: left">NLU</td>
      <td style="text-align: left">Natural Language Understanding</td>
      <td>Â </td>
    </tr>
    <tr>
      <td style="text-align: left">NLI</td>
      <td style="text-align: left">Natural Language Inference</td>
      <td>Â </td>
    </tr>
    <tr>
      <td style="text-align: left">BiDAF</td>
      <td style="text-align: left">Bidirection Attention Flow</td>
      <td>Â </td>
    </tr>
    <tr>
      <td style="text-align: left">BPE</td>
      <td style="text-align: left">Byte-Pair Encoding</td>
      <td>Â </td>
    </tr>
    <tr>
      <td style="text-align: left">TF-IDF</td>
      <td style="text-align: left">Term Frequencyâ€“Inverse Document Frequency</td>
      <td>Reflects how important a word is to a document in a collection or corpus</td>
    </tr>
    <tr>
      <td style="text-align: left">WMT</td>
      <td style="text-align: left">Workshop in Machine Translation</td>
      <td>Â </td>
    </tr>
    <tr>
      <td style="text-align: left">CoVe</td>
      <td style="text-align: left">Contextualized Word Vectors</td>
      <td>Â </td>
    </tr>
    <tr>
      <td style="text-align: left">HSIC</td>
      <td style="text-align: left">Hilbert-Schmidt Independence Criterion</td>
      <td>Â </td>
    </tr>
    <tr>
      <td style="text-align: left">PMI</td>
      <td style="text-align: left">Pointwise Mutual Information</td>
      <td>Â </td>
    </tr>
    <tr>
      <td style="text-align: left">UDA</td>
      <td style="text-align: left">Unsupervised Data Augmentation</td>
      <td>Â </td>
    </tr>
    <tr>
      <td style="text-align: left">RL2</td>
      <td style="text-align: left">Reinforcement Learning Fast &amp; Slow</td>
      <td>Â </td>
    </tr>
    <tr>
      <td style="text-align: left">MAML</td>
      <td style="text-align: left">Model-Agnostic Meta-Learning</td>
      <td>Â </td>
    </tr>
  </tbody>
</table>
:ET